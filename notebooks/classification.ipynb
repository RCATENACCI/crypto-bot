{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the root directory of your project to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.6.1\n",
      "NumPy version: 2.2.6\n",
      "SciPy version: 1.15.3\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import sklearn\n",
    "import numpy\n",
    "import scipy\n",
    "from binance.client import Client\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bot.utils import load_config\n",
    "import Feature_engineering\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n",
    "print(\"NumPy version:\", numpy.__version__)\n",
    "print(\"SciPy version:\", scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp            open            high             low  \\\n",
      "0 2022-01-01 00:00:00  46216.93000000  46527.26000000  46208.37000000   \n",
      "1 2022-01-01 00:15:00  46332.52000000  46421.27000000  46236.27000000   \n",
      "2 2022-01-01 00:30:00  46375.42000000  46689.42000000  46360.19000000   \n",
      "3 2022-01-01 00:45:00  46610.81000000  46731.39000000  46575.76000000   \n",
      "4 2022-01-01 01:00:00  46656.14000000  46767.24000000  46574.06000000   \n",
      "\n",
      "            close        volume  \n",
      "0  46332.51000000  386.65709000  \n",
      "1  46375.42000000  319.99973000  \n",
      "2  46610.81000000  386.08077000  \n",
      "3  46656.13000000  410.59336000  \n",
      "4  46766.99000000  330.08774000  \n"
     ]
    }
   ],
   "source": [
    "from bot.utils import load_config\n",
    "\n",
    "config=load_config(\"../config/config.yaml\")\n",
    "\n",
    "\n",
    "# Connexion au client Binance\n",
    "client = Client(config[\"api_key\"], config[\"api_secret\"])\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "klines = client.get_historical_klines(\n",
    "    symbol=config[\"symbol\"],\n",
    "    interval=Client.KLINE_INTERVAL_15MINUTE,\n",
    "    start_str=\"2022-01-01 00:00:00\",\n",
    "    end_str=\"2025-01-01 00:00:00\"\n",
    ")\n",
    "\n",
    "# Conversion en DataFrame Pandas\n",
    "columns = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "           \"close_time\", \"quote_asset_volume\", \"number_of_trades\",\n",
    "           \"taker_buy_base_asset_volume\", \"taker_buy_quote_asset_volume\", \"ignore\"]\n",
    "df = pd.DataFrame(klines, columns=columns)\n",
    "\n",
    "# Conversion du timestamp en format lisible\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n",
    "\n",
    "# Sélectionner uniquement les colonnes importantes\n",
    "df = df[[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "\n",
    "# Afficher les 5 premières lignes\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max=Feature_engineering.prepare_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp      open      high       low     close     volume  \\\n",
      "0 2022-01-01 08:15:00  47151.37  47344.69  47145.05  47305.23  183.98417   \n",
      "1 2022-01-01 08:30:00  47305.23  47313.91  47166.97  47210.18  109.50519   \n",
      "2 2022-01-01 08:45:00  47210.18  47260.00  47081.74  47124.82  107.04457   \n",
      "3 2022-01-01 09:00:00  47124.82  47215.56  47062.77  47205.77  127.12603   \n",
      "4 2022-01-01 09:15:00  47205.77  47205.78  47082.06  47094.74   85.76911   \n",
      "\n",
      "         sma_14        ema_14        macd  macd_signal  ...  rolling_mean  \\\n",
      "0  47137.470714  47087.855730  131.563458   137.119650  ...  47137.470714   \n",
      "1  47168.197857  47104.165633  130.061743   135.708068  ...  47168.197857   \n",
      "2  47150.032857  47106.919548  120.593656   132.685186  ...  47150.032857   \n",
      "3  47143.302143  47120.099609  118.258903   129.799929  ...  47143.302143   \n",
      "4  47136.315714  47116.718327  106.224906   125.084925  ...  47136.315714   \n",
      "\n",
      "   rolling_std  rolling_skew  rolling_kurt  close_lag1  close_lag2  \\\n",
      "0   165.568705     -0.595759      0.095309    47151.37    47194.73   \n",
      "1   130.281375     -0.195310     -0.783013    47305.23    47151.37   \n",
      "2   115.499519     -0.276342     -0.723691    47210.18    47305.23   \n",
      "3   108.629241     -0.339007     -0.444414    47124.82    47210.18   \n",
      "4   108.363222     -0.132021     -0.497359    47205.77    47124.82   \n",
      "\n",
      "   close_lag3  close_lag4  return_future  target  \n",
      "0    47096.70    46959.61      -0.002009       0  \n",
      "1    47194.73    47096.70      -0.001808       0  \n",
      "2    47151.37    47194.73       0.001718       1  \n",
      "3    47305.23    47151.37      -0.002352       0  \n",
      "4    47210.18    47305.23      -0.002257       0  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_max.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'open', 'high', 'low', 'close', 'volume', 'sma_14',\n",
      "       'ema_14', 'macd', 'macd_signal', 'macd_diff', 'rsi', 'stoch_k',\n",
      "       'stoch_d', 'roc', 'atr', 'bollinger_mavg', 'bollinger_hband',\n",
      "       'bollinger_lband', 'bollinger_width', 'obv', 'mfi', 'rolling_mean',\n",
      "       'rolling_std', 'rolling_skew', 'rolling_kurt', 'close_lag1',\n",
      "       'close_lag2', 'close_lag3', 'close_lag4', 'return_future', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_max.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any columns you don't want as features (like \"return_future\" or raw \"target\" if present)\n",
    "feature_cols = [col for col in df_max.columns if col not in [\"target\", \"return_future\",\"timestamp\"]]\n",
    "X = df_max[feature_cols]\n",
    "y = df_max[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your full dataset into train and test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Then split X_train_full into actual training and validation set (80/20 again)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:04:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_estimators=1000,         # max trees\n",
    "    max_depth=6,               # reset to default\n",
    "    learning_rate=0.05,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5280\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    sell (0)       0.53      0.51      0.52     10455\n",
      "     Buy (1)       0.53      0.54      0.54     10581\n",
      "\n",
      "    accuracy                           0.53     21036\n",
      "   macro avg       0.53      0.53      0.53     21036\n",
      "weighted avg       0.53      0.53      0.53     21036\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x11c5977a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAGwCAYAAAAe3Ze+AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAASjRJREFUeJzt3Qd0VFX38OGdQhIIJLRAQCJVqoSmIggIglQbtk+kiRThBRGU+ipIE3xBREABBRELiojlrwGRJr0p0jsEJHQNJYSSkPKtfXTGDCTjHWZCkuH3uO7KzL1nbu5kYWZn733O9UlNTU0VAAAAN/m6ewIAAABFUAEAADyCoAIAAHgEQQUAAPAIggoAAOARBBUAAMAjCCoAAIBH+HvmNDlbSkqKHD9+XPLlyyc+Pj5ZfTkAABfpkksXLlyQ4sWLi69v5vy9fOXKFUlMTPTIuQICAiQoKEi8DUGFiAkoIiIisvoyAABuiomJkRIlSmRKQJE7XyGRpEseOV94eLgcOnTI6wILggoRk6FQD4z5XvyDgrP6coBM0adBmay+BCDTXIq/IE/eH2n/fe5pJkORdEkCK3cU8Qtw72TJiXJy18fmnAQVXshW8tCAIlfuvFl9OUCmCM4bktWXAGS6TC9h+weJj5tBRaqP97YzElQAAGCVxizuBi4+4rUIKgAAsEqzDO5mGny8N1Phve8MAADcVGQqAACwSksfbpc/fMRbEVQAAGAV5Q+nvPedAQCAm4pMBQAAVlH+cIpMBQAAlv1d/nBnE9c+eocNG2bW30i7VaxY0Rw7fPjwdcds21dffWU/x5EjR6RVq1aSJ08eKVKkiPTv31+SkpIcvs/y5culZs2aEhgYKOXKlZNZs2a5/NMhUwEAQDZXpUoVWbJkif25v/9fH996i4kTJ044jP3ggw9k3Lhx0qJFC/M8OTnZBBS6NPjatWvN+A4dOkiuXLlk9OjRZowuGa5junfvLrNnz5alS5dKly5dpFixYtKsWTPL10lQAQBANi9/+Pv7m6DgWn5+ftft//bbb+Xpp5+WvHn/WiF60aJFsmvXLhOUFC1aVKpXry4jR46UgQMHmiyI3txs2rRpUrp0aRk/frx5TaVKlWT16tUyYcIEl4IKyh8AAFjlbunD55/ZI3FxcQ5bQkJCht92//795g6sZcqUkbZt25pyRno2bdokW7Zskc6dO9v3rVu3TqpWrWoCChsNFPR77ty50z6mSZMmDufSMbrfFQQVAABkgYiICAkNDbVvY8aMSXdc7dq1TX/DwoULZerUqaZUUb9+fXOr92t9+OGHJstQt25d+76TJ086BBTK9lyPORujgcfly5ctvyfKHwAAZEH5IyYmRkJC/rnRnzZIpsfWG6EiIyNNkFGyZEmZO3euQ0ZCP/w///xzGTJkiGQVggoAALJg8auQkBCHoMKq/PnzS/ny5eXAgQMO++fNmyeXLl0yTZhpac/Fxo0bHfadOnXKfsz21bYv7Ri9vty5c1u+NsofAAC4mqlwd3NDfHy8HDx40MzMuLb08cgjj0hYWJjD/jp16sj27dvl9OnT9n2LFy82AUPlypXtY3TGR1o6Rve7gqACAIBsrF+/frJixQqzJoVOCW3durWZ9dGmTRv7GM1arFy50kwDvVbTpk1N8NC+fXvZunWr/PTTT/Laa69Jz5497SUXnUoaHR0tAwYMkD179siUKVNMeaVv374uXSvlDwAAsvG9P44ePWoCiNjYWJOFqFevnqxfv94hIzFz5kwpUaKECSCupQFIVFSU9OjRw2QegoODpWPHjjJixAj7GJ1OOn/+fBNETJw40ZxrxowZLk0nNW8tNTU1VW5x2t2qnbdNJyyVXLn/mtcLeJsBjcpl9SUAmeZifJy0rFVazp8/f0N9ClY/JwLrDhYf/yC3zpWadEUS1o7JtGvNSpQ/AACAR1D+AADAKl+fvzZ3z+GlCCoAAMjGPRU5ife+MwAAcFORqQAAIJvfUCynIKgAAMAqyh9Oee87AwAANxWZCgAArKL84RRBBQAAVlH+cIqgAgAAq8hUOOW94RIAALipyFQAAGAV5Q+nCCoAALCK8odT3hsuAQCAm4pMBQAAlnmg/CHe+/c8QQUAAFZR/rhFwyUAAHBTkakAAMClTIW7sz98xFsRVAAAYBVTSp3y3ncGAABuKjIVAABYRaOmUwQVAABYRfnDKYIKAACsIlPhlPeGSwAA4KYiUwEAgFWUP5wiqAAAwCrKH055b7gEAABuKjIVAABY5OPjYzY3TyLeiqACAACLCCqco/wBAAA8gkwFAABWaZLB3USDj3gtMhUAALhY/nB3c8WwYcOue33FihUdxqxbt04eeOABCQ4OlpCQEGnQoIFcvnzZfvzMmTPStm1bcyx//vzSuXNniY+PdzjHtm3bpH79+hIUFCQREREyduxYcRWZCgAAsrkqVarIkiVL7M/9/f0dAormzZvL4MGDZfLkyebY1q1bxdf3n7yBBhQnTpyQxYsXy9WrV6VTp07SrVs3+fzzz83xuLg4adq0qTRp0kSmTZsm27dvl+eff94EIDrOKoIKAACyeaOmv7+/hIeHp3usb9++0rt3bxk0aJB9X4UKFeyPd+/eLQsXLpRffvlF7rrrLrNPg4+WLVvKW2+9JcWLF5fZs2dLYmKizJw5UwICAkwQs2XLFnn77bddCioofwAAkAXlj7i4OIctISEhw++7f/9+8+FfpkwZk3U4cuSI2X/69GnZsGGDFClSROrWrStFixaV+++/X1avXu2QydCMgy2gUJqR0EyGvtY2RksmGlDYNGvWTPbu3Stnz561/PMhqAAAIAuCioiICAkNDbVvY8aMSfd71q5dW2bNmmWyDVOnTpVDhw6Z3ocLFy5IdHS0ve+ia9euZkzNmjWlcePGJhBRJ0+eNEHHtZmPggULmmO2MRqQpGV7bhtjBeUPAACyQExMjGmctAkMDEx3XIsWLeyPIyMjTZBRsmRJmTt3rlSqVMnsf+GFF0yfhKpRo4YsXbrUlDIyClQyC5kKAABcnVLq7iZiAoq0W0ZBxbW0lFG+fHk5cOCAFCtWzOyrXLmywxgNNmwlEu3F0DJJWklJSWZGiK1PQ7+eOnXKYYzteUa9HOkhqAAAIBtPKb2WTgU9ePCgCShKlSplei209yGtffv2mWyGqlOnjpw7d042bdpkP75s2TJJSUkxWQ/bmJUrV5qZITY6U0QbPgsUKCBWEVQAAJCN9evXT1asWCGHDx+WtWvXSuvWrcXPz0/atGljApT+/fvLpEmTZN68eSZ7MWTIENmzZ49Zi8KWtdApp9pzsXHjRlmzZo306tVLnnnmGROQqGeffdY0aeprdu7cKV9++aVMnDhRXn75ZZeulZ4KAABcuvO5u1NKxSVHjx41AURsbKyEhYVJvXr1ZP369eax6tOnj1y5csVMLdWSRrVq1UyWoWzZsvZz6JRRDSS0gVNnfTzxxBMmELHRRtFFixZJz549pVatWlK4cGEZOnSoS9NJzVtLTU1NlVucTuXRH2jTCUslV+68WX05QKYY0KhcVl8CkGkuxsdJy1ql5fz58w7Nj57+nMj/9HTxCcjj1rlSEy/JubldM+1asxLlDwAA4BGUPwAAsIhbnztHUAEAgFXcpdQpyh8AAMAjyFQAAGCVB8ofqZQ/AACAJ3oqfAgqAAAAQYVz9FQAAACPIFMBAIBVzP5wiqACAACLKH84R/kDAAB4BJkKAAAsIlPhHEEFAAAWEVQ4R/kDAAB4BJkKAAAsIlPhHEEFAABWMaXUKcofAADAI8hUAABgEeUP5wgqAACwiKDCOYIKAAAsIqhwjp4KAADgEWQqAACwitkfThFUAABgEeUP5yh/AAAAjyBTgRvydI3b5OmatznsO3busrz09XbzuNt9pSSyeIgUyBMgV64my77T8fLpLzFy/PwVc7zhHYWlV4My6Z77+dm/SdyVJId9FYrklRGtKsmRs5ek/3c7M+19ATaffrVMPpu33GFfieKF5cMJvc3jxMSr8sGnP8nytdvl6tVkqVWtnLzY+SEpkD+vffzeA8dk5heLZH/0CdE/TiuUvU06t20mZUuF288xacYPsj/6uBw59qfUrllehvV/9ia/U7iCTMUtEFQcPnxYSpcuLZs3b5bq1avL8uXLpVGjRnL27FnJnz9/Vl+e19IP+BE/7rU/T05JtT+O/vOirDoYK3/GJ0jeQH8ThAxpXkF6zt0qOmxtdKxsOXre4Xw9G5SWAD/f6wKKPAF+8uL9ZWT78TgJze0V/2SRQ5QsUUTeHNLR/tzP95/k7rRPFsrG3/bJa33/nwTnCZL3ZkbJiPFfyISRXc3xy1cS5NUxn8i9tSpKr84PS3JyiglUXh39iXw25RXx9/eTlJRUCQjIJY+2uFdWb9iVJe8RrvERDwQV4r1BBeUP3DANIs5dvmrfLiT8Ewws2fuH7D55Qf6IT5RDsZdkzqajEpY30GwqMdnxtSmpqXJnsRBZuu+P677PC/eVktUHY022A7iZ/Px8pWD+fPYtNCTY7L946Yr8tOw3eaFDc6l+Zxm5o0xxeblHa9m1L0Z274sxY2KO/SkX4i9Lh6cfkIjihaVURBFp92QjOXs+Xk79ec6MCQoKkN5dHpaWje+SgmkyHEBORVCBG1YsJEg+eKa6vPdUpLx0fxkpHByQ7rhAf19pVD5MTsVdkdiLiemOub9cYUlMSpH1h8447G90R2Epki9Q5m4+linvAXDm2MlYadN9nHR8cYK8OWmenP47GNByRVJystSo+k8J7/bbwqRI4VDZvT/GXioJyZdHfvp5k1xNSpKExKuycNkmMy48jAxqTi9/uLt5q2wVVMybN0+qVq0quXPnlkKFCkmTJk3k4sWL5tiMGTOkUqVKEhQUJBUrVpQpU6Zk9eXe0vb/ES/vrYyWN37aKx+s/d188I98qJIE5frnn1SzSkXk0w61ZHbHu6RGiVAZsXCvJKUpkaT1QPkwWRUdazIYNuEhgdL27giZtDzalEyAm6liuRLSr0dreWNwe9MrcfKPs/LK6x/KpcsJcuZcvOTy95O8wbkdXpM/NK85pvLkDpRxQzvJ0lXb5JF2I+WxDqPk160HZNTg9uLn55dF7woem1Lq7ualsk2B+sSJE9KmTRsZO3astG7dWi5cuCCrVq2S1NRUmT17tgwdOlTeffddqVGjhumd6Nq1qwQHB0vHjv/UO61KSEgwm01cXJyH343325ymH+L3s5dNkDH1/1WTuqULyrJ9f5r9qw7EytZj502z5iN3hsvLD5ST16J2ydU0gYMqXySvRBTILZNXHLTv8/UR6dOwrMz97aiciPuruRO4me6uUd7+uEzJcKl4Rwlp3/NtWbluh+mD+DeamXj7/e+kSoXbZXDvpyQlJUXmRa2RIW9+JpPHvCCBFs4B5DTZKqhISkqSxx9/XEqWLGn2adZCvf766zJ+/HhzTGlT5q5du+T999+/oaBizJgxMnz4cA+/g1vbpcRkOXH+ioSHBP2z72qy2U7GJcj+0/Eyq11NuadkAVkT7VjiaFw+TA7FXpTo2Ev2fUG5/KRcWF4pXShYOtcpZfZpxtDXx0e+7HS3jFy4R3acuHAT3yFudZqVKFGskBw/eUZqRpaVq0nJEn/xskO24tz5eHtvxM+rt8mpP87JOyO7iu/fDZ6Dej8pTzw/Rtb9skca3vfX7zfkLMz+yCHlj2rVqknjxo1NIPHUU0/J9OnTzewNLX8cPHhQOnfuLHnz5rVvo0aNMvtvxODBg+X8+fP2LSbmrxooblyQv68UDQmSc5euZjhG/z/K5ed73es0u7F0r2OD5uXEZOn7zXbp990O+7Zoz2kzbVUf7//jr7IYcLPobI7jp85KwQL5TGOmv5+fbN4RbT8ec/xPOf3neal0R4R5npBw1QTBaT9AzHPxMY3JyJmyoqdi2LBh171e2wBsGjZseN3x7t27O5zjyJEj0qpVK8mTJ48UKVJE+vfvb/6QT0tnTtasWVMCAwOlXLlyMmvWrJybqdAa4+LFi2Xt2rWyaNEimTx5srz66qvyww8/mOMaZNSuXfu619wI/YHphhvX4Z4I+fXIOfkjPkEK5gkwa1bo9LjV0bGmv+K+0gVN6UOnhxYKDpDHIotJYlKq/BbzV6ObTd0yBcXX10dWHox12K+/cmPOXnbYF3c5SRKTU67bD2SGDz5dKPfWqiBFCueX2LMXzHRQP18fk2HQKaTNHqgpH3yyUPIF5/5rSulH86VS+QizqRqRZWX67EXy7odR8mjze00gMff/VpkZJdWqlLZ/n9+PnpakpGQzU0T7NQ4ePmH2ly1VLMveOzKm8YC7iQafG3h9lSpVZMmSJfbn/v6OH9/aEjBixAj7cw0ebJKTk01AER4ebj5jtTLQoUMHyZUrl4wePdqMOXTokBmjwYi2HCxdulS6dOkixYoVk2bNmuW8oEJpdHXfffeZTXsotAyyZs0aKV68uERHR0vbtm2z+hLxNw0UtOchX5C/CRz2nLog//1hl3msv3grheeTVneGS3CAn5y/fNVML3016q/j15Y+Nh4+Y8onQHbyZ2ycjJk0Ty5cuGSmkmpvxDujukn+v6eVdu/Q3GQeRr79pZndcVdkOenV5SH763WWx/ABz8rseculz5Dp5vdbudLhpvGzUIF89nHaY6FlEpv/DJxqvv705T8fEPBOcdf08zn7g1eDCA0KMqJBREbH9Q91bRnQoKRo0aJmPaeRI0fKwIEDTRYkICBApk2bZloLtNVA6cSI1atXy4QJE3JmULFhwwYTGTVt2tSkZvT5H3/8Yd6Y9j/07t1bQkNDpXnz5qbJ8tdffzXlkZdffjmrL/2WNOHnjEtPZy9dldGL9lk6z6tRuy1/T51WytRS3Cz/7fO00+ParNmr80Nmy0ityHJmc+aTd/kdlvMyFe72VIgREfFXVstG+wf1Qz49+/fvN39g6wzIOnXqmN7A22+/3X5cswufffaZCSwefvhhGTJkiD1bsW7dOtNaoAGFjQYKPXr0kJ07d5oJEDpGZ1ympWP69Onj0nvLNkFFSEiIrFy5Ut555x0TvWmWQiOmFi1amOP6wxk3bpypA+msD/0BufpmAQBwiwfKH/L367WfTz/7bDLKUmjpX/sbKlSoYEoX+od2/fr1ZceOHZIvXz559tlnzWemBh3btm0zGYi9e/fKN998Y15/8uRJh4BC2Z7rMWdj9PP48uXLZqmHHBVUaEZi4cKFGR7XH5pu6SlVqpSZepq2aSXtcwAAspuQkBCHoCIjtj+uVWRkpAkyNIiYO3eumcTQrVs3+3H9g1v7IHTig05mKFu2rNySsz8AAMjussOKmvnz55fy5cvLgQMH0j1um9RgO64lkVOnTjmMsT239WFkNEaDHqtZCkVQAQCAi7M/3N3cER8fb7IQmpFIz5YtW8xX23Htwdi+fbucPn3aPkZnW2rAULlyZfsY7WtMS8foflcQVAAAkI3169dPVqxYYe7IrVNCddVpXVJBV6HW4EJncmzatMkc//7778100QYNGphSidIJEBo8tG/fXrZu3So//fSTvPbaa9KzZ097H4dOJdVZlgMGDJA9e/aYW2FoeaVv374uXWu26akAACC703V1dHNHqouvP3r0qAkgYmNjJSwsTOrVqyfr1683j69cuWKmiuokB10sUmeUPPHEEyZosNEAJCoqysz20MyD7RYXade10Omk8+fPN0HExIkTpUSJEuaeW65MJ1UEFQAAZOPFr+bMmZPhMQ0iNIvxb7Sxc8GCBU7H6CQHvbeWOyh/AAAAjyBTAQCARdxQzDmCCgAAsvm9P3IKggoAACwiU+EcPRUAAMAjyFQAAGARmQrnCCoAALCIngrnKH8AAACPIFMBAIBFPuKB8od4b6qCoAIAAIsofzhH+QMAAHgEmQoAACxi9odzBBUAAFhE+cM5yh8AAMAjyFQAAGAR5Q/nCCoAALCI8odzBBUAAFhEpsI5eioAAIBHkKkAAMAqD5Q/xHsTFQQVAABYRfnDOcofAADAI8hUAABgEbM/nCOoAADAIsofzlH+AAAAHkGmAgAAiyh/OEdQAQCARZQ/nKP8AQAAPIJMBQAAFpGpcI6gAgAAi+ipcI6gAgAAi8hUOEdPBQAA8AiCCgAAXCx/uLu5YtiwYfYMiW2rWLHideNSU1OlRYsW5vh3333ncOzIkSPSqlUryZMnjxQpUkT69+8vSUlJDmOWL18uNWvWlMDAQClXrpzMmjVLXEX5AwCAbF7+qFKliixZssT+3N//+o/vd955J91zJycnm4AiPDxc1q5dKydOnJAOHTpIrly5ZPTo0WbMoUOHzJju3bvL7NmzZenSpdKlSxcpVqyYNGvWzPJ1ElQAAJAF4uLiHJ5rhkC39GgQoUFBRrZs2SLjx4+XX3/91QQCaS1atEh27dplgpKiRYtK9erVZeTIkTJw4ECTBQkICJBp06ZJ6dKlzTlUpUqVZPXq1TJhwgSXggrKHwAAWKR5ALfLH/KXiIgICQ0NtW9jxozJ8Pvu379fihcvLmXKlJG2bduacobNpUuX5Nlnn5X33nsv3cBj3bp1UrVqVRNQ2GigoEHNzp077WOaNGni8Dodo/tdQaYCAACLfH18zObuOVRMTIyEhISITUZZitq1a5v+hgoVKpjSxfDhw6V+/fqyY8cOyZcvn/Tt21fq1q0rjz76aLqvP3nypENAoWzP9ZizMRp4XL58WXLnzi1WEFQAAJAFQkJCHIKKjGjzpU1kZKQJMkqWLClz586VsLAwWbZsmWzevFmyA8ofAABk49kf18qfP7+UL19eDhw4YAKKgwcPmn3ad2Fr4HziiSekYcOG5rGWRE6dOuVwDttzW7kkozEa9FjNUiiCCgAALLp2aueNbu6Ij483gYQ2ZA4aNEi2bdtmGjVtm9IGy48++sg8rlOnjmzfvl1Onz5tP8fixYtNwFC5cmX7GJ3xkZaO0f2uoPwBAIBFvj5/be6ewxX9+vWThx9+2JQ8jh8/Lq+//rr4+flJmzZtTPkjvebM22+/3czmUE2bNjXBQ/v27WXs2LGmf+K1116Tnj172vs4dCrpu+++KwMGDJDnn3/eZEC0vDJ//nyXrpWgAgCAbOzo0aMmgIiNjTVBRL169WT9+vXmsRUagERFRUmPHj1M5iE4OFg6duwoI0aMsI/RAEQDCG36nDhxopQoUUJmzJjh0nRSRVABAIBVpifC3TuKiUvmzJnj0nhdWfNamuVYsGCB09dpD4a7DZ8EFQAAWMRdSp2jURMAAHgEmQoAACzy+fs/d8/hrQgqAADIxrM/chLKHwAAwCPIVAAAkM1vfZ5TEFQAAGARsz88EFR8//33YtUjjzxieSwAALjFgorHHnvMckonOTnZ3WsCAMDrb31+ywYVKSkpmX8lAABkc5Q/MrGn4sqVKxIUFOTOKQAAyDFo1PTwlFItb4wcOVJuu+02yZs3r0RHR5v9Q4YMkQ8//NDV0wEAgFs1qHjjjTdk1qxZ5vapAQEB9v133nmnuaMZAADeylb+cHfzVi4HFZ988ol88MEH0rZtW3M7VZtq1arJnj17PH19AABku0ZNdzdv5XJQcezYMSlXrly6zZxXr1711HUBAABvDyoqV64sq1atum7/vHnzpEaNGp66LgAAsh0fD23eyuXZH0OHDpWOHTuajIVmJ7755hvZu3evKYtERUVlzlUCAJANMPvDw5mKRx99VH744QdZsmSJBAcHmyBj9+7dZt+DDz7o6ukAAMCtvE5F/fr1ZfHixZ6/GgAAsjFufZ5Ji1/9+uuvJkNh67OoVavWjZ4KAIAcgfKHh4OKo0ePSps2bWTNmjWSP39+s+/cuXNSt25dmTNnjpQoUcLVUwIAgFuxp6JLly5m6qhmKc6cOWM2faxNm3oMAABvxsJXHsxUrFixQtauXSsVKlSw79PHkydPNr0WAAB4K8ofHg4qIiIi0l3kSu8JUrx4cVdPBwBAjkGjpofLH+PGjZMXX3zRNGra6OOXXnpJ3nrrLVdPBwAAbqVMRYECBRzSNRcvXpTatWuLv/9fL09KSjKPn3/+eXnssccy72oBAMhClD88EFS88847VoYBAODVPLHMto/IrR1U6LLcAAAAmbL4lbpy5YokJiY67AsJCXHnlAAAZFueuHW5rxeXP1xu1NR+il69ekmRIkXMvT+03yLtBgCAt3J3jQofL1+rwuWgYsCAAbJs2TKZOnWqBAYGyowZM2T48OFmOqneqRQAAHjOsGHD7A2itq1ixYr24y+88IKULVtWcufOLWFhYebGn3v27HE4x5EjR6RVq1aSJ08ekxTo37+/mWSR1vLly6VmzZrms71cuXIya9aszC9/6N1INXho2LChdOrUySx4pd+8ZMmSMnv2bGnbtq3LFwEAQE6QVbM/qlSpYu4ObmObfan03lv62Xv77bebVa41CGnatKkcOnRI/Pz8zDpSGlCEh4ebxStPnDghHTp0kFy5csno0aPNOXSsjunevbv5LF+6dKlZJbtYsWLSrFmzzAsq9ILLlClj75/Q56pevXrSo0cPV08HAECO4Ynyhc8NvF6DCA0K0tOtWzf741KlSsmoUaOkWrVqcvjwYZPBWLRokezatcsEJUWLFpXq1avLyJEjZeDAgSYACQgIkGnTpknp0qVl/Pjx5jyVKlWS1atXy4QJE1wKKlwuf2hAoRGN0vTL3Llz7RkM2w3GAACAc3FxcQ5bQkJChmP3799v2gz0M1izElrOyKjv8aOPPjIBgq6ArdatWydVq1Y1AYWNBgr6PXfu3Gkf06RJE4dz6Rjd7wqXgwoteWzdutU8HjRokLz33nsSFBQkffv2NTUaAAC8ffaHu5vSD/3Q0FD7NmbMGEmPLjap/Q0LFy40/Yz6h722Hly4cME+ZsqUKZI3b16z/fjjj7J48WKTgVAnT550CCiU7bkeczZGA4/Lly9LppU/NHiw0ahGm0E2bdpk+ioiIyNdPR0AALdk+SMmJsZhGQZtkExPixYt7I/1c1aDDO1j1EpB586dzX7NXjz44IOmX0JvmfH000/LmjVrzB/9OWadCqVvTDcAALydJxs1Q0JCbmhtJ201KF++vBw4cMC+z5btuOOOO+Tee+81Szx8++230qZNG9OLsXHjRodznDp1yny19WnoV9u+tGP0+nRWiUeDikmTJlk+Ye/evS2PBQAAromPj5eDBw9K+/bt0z2emppqNluPRp06deSNN96Q06dPm+mkSssjGjBUrlzZPmbBggUO59Exut8VloIK7f60Gn3l5KDi0w53sSIovFaBu3tl9SUAmSY12XF158zieyPNiNdw9fX9+vWThx9+2FQFjh8/Lq+//rqZKqpZiOjoaPnyyy/NFFJdo+Lo0aPy5ptvmuxCy5Ytzev1mAYPGoSMHTvW9E+89tpr0rNnT3vJRaeSvvvuu2YtKr05qK5HpeWV+fPnez6osM32AADgVpYV61QcPXrUBBCxsbEmcNAlHNavX28eX716VVatWmVu/Hn27FnTXNmgQQOzHoUtK6EBSFRUlFn2QTMPuhq23tNrxIgR9u+hs0U0gNC+yYkTJ0qJEiXM4pauTCf1SE8FAADIPHPmzMnwmE4zvbZskR7NcvzbOF3UcvPmzeIOggoAACzSJINvFix+lVMQVAAAYJGvB4IKXy8OKtztNwEAADDIVAAAkM1vKObVmQrtNG3Xrp3pIj127JjZ9+mnn5qbjwAA4O3lD3c3b+VyUPH111+bKSY6B1a7RG2La5w/f95+C1UAAHDrcTmo0Fuq6i1Sp0+fbu7FbnPffffJb7/95unrAwAg2937w93NW7ncU7F3716zsMa1dM3xc+fOeeq6AADIdtLeZdSdc3grlzMVetORtDcxsdF+Cr3POwAA3srXQ5u3cvm9de3aVV566SXZsGGD6WDVdchnz55t1ibXJUABAMCtyeXyx6BBgyQlJUUaN24sly5dMqUQvSGJBhUvvvhi5lwlAADZgCd6Iny8t/rhelCh2YlXX31V+vfvb8ogegtWvftZ3rx5M+cKAQDIJnzFAz0V4r1RxQ0vfhUQEGC/DzsAAIDLQUWjRo2crgam92AHAMAbUf7wcFBRvXp1h+d6L/ctW7bIjh07zP3ZAQDwVtxQzMNBxYQJE9LdP2zYMNNfAQAAbk0emy6r9wKZOXOmp04HAEC2o6UL2wJYN7r5kKn4d+vWrZOgoCBPnQ4AgGyHngoPBxWPP/64w/PU1FQ5ceKE/PrrrzJkyBBPXhsAAPDmoELv8ZGWr6+vVKhQQUaMGCFNmzb15LUBAJCt0KjpwaAiOTlZOnXqJFWrVpUCBQq48lIAAHI8n7//c/cc3sqlRk0/Pz+TjeBupACAWzlT4e7mrVye/XHnnXdKdHR05lwNAAC4dYKKUaNGmZuHRUVFmQbNuLg4hw0AAG9FpsJDPRXaiPnKK69Iy5YtzfNHHnnEYblunQWiz7XvAgAAb6Sfc85uVWGFu6/3iqBi+PDh0r17d/n5558z94oAAIB3BxWaiVD3339/Zl4PAADZFlNKPTil1JtTNgAA/BtW1PRgUFG+fPl/DSzOnDnjyikBAMCtGFRoX8W1K2oCAHCrsN0UzN1zeCuXgopnnnlGihQpknlXAwBANkZPhYfWqaCfAgCAm2/YsGH2qay2rWLFivaWgxdffNHcgyt37txy++23S+/eveX8+fMO5zhy5Ii0atVK8uTJY5ID/fv3l6SkJIcxy5cvl5o1a0pgYKCUK1dOZs2alfmzPwAAuGV5oFFTbuD1VapUkSVLltif+/v/9fF9/Phxs7311ltSuXJl+f33383yD7pv3rx5ZoyuH6UBRXh4uKxdu9YsXNmhQwfJlSuXjB492ow5dOiQGaOvnT17tixdulS6dOkixYoVk2bNmnk+qEhJSXHl/QMA4HV8xcds7p7DVRpEaFCQ3q0zvv76a/vzsmXLyhtvvCHt2rUzmQh93aJFi2TXrl0mKClatKhUr15dRo4cKQMHDjRZkICAAJk2bZqULl1axo8fb85TqVIlWb16tUyYMMGloMLlZboBALjVp5S6u6lrb3ORkJAgGdm/f78UL15cypQpI23btjXljIxo6SMkJMSezVi3bp25u7gGFDYaKOj33Llzp31MkyZNHM6jY3S/KwgqAADIAhEREWZGpW0bM2ZMuuNq165t+hsWLlwoU6dONaWK+vXry4ULF64b++eff5osRLdu3ez7Tp486RBQKNtzPeZsjAYely9fzpzZHwAA3Mo8OfsjJibGZBRstEEyPS1atLA/joyMNEFGyZIlZe7cudK5c2f7MQ0AtC9Ceyu0rJEVCCoAAMiCdSpCQkIcggqr8ufPbxajPHDggH2fZi2aN28u+fLlk2+//dY0YdpoL8bGjRsdznHq1Cn7MdtX2760Y/T6dFaJ5ffm8rsBAABZJj4+Xg4ePGhmZtgyFE2bNjUNl99//70EBQU5jK9Tp45s375dTp8+bd+3ePFiEzBoVsM2Rmd8pKVjdL8rCCoAAMiCRk2r+vXrJytWrJDDhw+bKaGtW7cWPz8/adOmjT2guHjxonz44YfmufZH6KZTSZUe1+Chffv2snXrVvnpp5/ktddek549e9pLLjqVNDo6WgYMGCB79uyRKVOmmPJK3759xRWUPwAAcGVKqc/NnVJ69OhRE0DExsZKWFiY1KtXT9avX28e64JVGzZsMON0waq0tKGzVKlSJgCJioqSHj16mMxDcHCwdOzYUUaMGGEfq9NJ58+fb4KIiRMnSokSJWTGjBkuTSdVBBUAAGRjc+bMyfBYw4YNLS1OqY2dCxYscDpGz7V582ZxB0EFAAAWcetz5wgqAABwoRHR3WZEX/Fe3vzeAADATUSmAgAAi2x3CXX3HN6KoAIAAIs0HMiCm5TmGAQVAABkwYqa3oieCgAA4BFkKgAAcIH35hncR1ABAIBFrFPhHOUPAADgEWQqAACwiCmlzhFUAABgEStq3rrvDQAA3ERkKgAAsIjyh3MEFQAAWMSKms5R/gAAAB5BpgIAAIsofzhHUAEAgEXM/nCOoAIAAIvIVNy6ARMAALiJyFQAAGARsz+cI6gAAMAibijmHOUPAADgEWQqAACwyFd8zObuObwVQQUAABZR/nCO8gcAAPAIMhUAAFjk8/d/7p7DWxFUAABgEeUP5yh/AAAAjyBTAQCAC6ULd2dv+FD+AAAAlD+co/wBAICLQYW7myuGDRtmv5GZbatYsaL9+AcffCANGzaUkJAQc+zcuXPXnePMmTPStm1bMyZ//vzSuXNniY+Pdxizbds2qV+/vgQFBUlERISMHTtWXEVQAQBANlelShU5ceKEfVu9erX92KVLl6R58+by3//+N8PXa0Cxc+dOWbx4sURFRcnKlSulW7du9uNxcXHStGlTKVmypGzatEnGjRtnghkNWFxB+QMAgCyYUhoXF+ewPzAw0Gzp8ff3l/Dw8HSP9enTx3xdvnx5usd3794tCxculF9++UXuuusus2/y5MnSsmVLeeutt6R48eIye/ZsSUxMlJkzZ0pAQIAJYrZs2SJvv/22Q/Dxb8hUAABgka+PZzalJYbQ0FD7NmbMGMnI/v37zYd/mTJlTNbhyJEjYtW6detMycMWUKgmTZqIr6+vbNiwwT6mQYMGJqCwadasmezdu1fOnj1r+XuRqQAAIAvExMSYHgebjLIUtWvXllmzZkmFChVM6WP48OGm92HHjh2SL1++f/0+J0+elCJFilyX+ShYsKA5ZhtTunRphzFFixa1HytQoICl90RQAQBAFpQ/QkJCHIKKjLRo0cL+ODIy0gQZ2vswd+5c03CZnRBUAACQg6aU5s+fX8qXLy8HDhywNF57MU6fPu2wLykpycwIsfVp6NdTp045jLE9z6iXIz30VAAAkIPEx8fLwYMHpVixYpbG16lTx0wz1VkdNsuWLZOUlBST9bCN0RkhV69etY/RmSJacrFa+lAEFQAAWOSTpgRy4/+5pl+/frJixQo5fPiwrF27Vlq3bi1+fn7Spk0be8+DztSwZS62b99unmsmQlWqVMlMOe3atats3LhR1qxZI7169ZJnnnnGNH+qZ5991jRpajlFp55++eWXMnHiRHn55ZddulbKHwAAWJR29oY753DF0aNHTQARGxsrYWFhUq9ePVm/fr15rKZNm2aaN210Fof66KOP5LnnnjOPdcqoBhKNGzc2sz6eeOIJmTRpkv01Ovtk0aJF0rNnT6lVq5YULlxYhg4d6tJ0UuWTmpqaKrc4nSusP9BTsectNc0AOVGBu3tl9SUAmSY1OVEStk+X8+cz5/e47XNiwaZDEpzXvfNfjI+TlrVKZ9q1ZiUyFXDbhFmLZMR730v3ZxrKmFeeNPtO/RknQyd9K8s37JH4SwlSrmQReeX5ZvLIAzWue31C4lVp8txbsmP/MVn52SCpWqGE/djSdbvkzQ8WyJ7oExIYkEvq1igro/o8LrcXL3RT3yNuPQO7tpRB3Vo67Nt3+KTUfmqURBQrKNu+H5Hu654b9KH839LNUiA0WD4Y2VGqlLtNCobmkT/PxsuCFdtk5JQf5MLFK2bsvdXKyLAXH5U7SoZL7qBcEnPyjMz6Zo1M/eLnm/IekbWzP7wRQQXc8tvO32XWt2ukyh23OezvMewTOX/hsnz+9gtSKDSvzPvpV+k0eKb8/MkAiawQ4TD29Un/J+FhoSaoSOv3Y39K234fyH+efcD8co6LvyL/fftraT9guqz4bNBNeX+4te0+eFwe6znZ/jwpKcV8PXbqrFRoPthhbMfW98mL7ZrIkrU7zXNtgvtxxTZ5Y2qUxJ69IKUjwmTcgKelQEiwdB0yy4y5eDlRps9dKTsPHDOP61QvK28PfkYuXUmUj79dc1PfK3LO7I/sLEsbNbXWk/YGKYUKFTLNJHpTE2R/moHoNnSWTPxvG8mfL7fDsY3boqXr/7tfalUpJaVKFJZ+nZtLaL7csmV3jMO4xWt2ys8bdsvIl1pfd/4te2IkOTlFXuvxkJQuESbVKkZIr3aNZfu+Y3I1KTnT3x+QlJwip2Mv2Lcz5y+a/SkpqQ77dXuoYTX5bslvJjhQGlTP/Hq1bNl9RGJOnpWVv+yTD+etkjo1ytrPv33fUfl60SbZE31SYk6ckbk//iLL1u82wQWyc6Om+5u3yvLZHxpE2G6QsnTpUrPK10MPPZTVlwUL+o/9Upred6c0rP3P3fJs7oksI98u3iRnz180f7F9vehXSUhIknq17rCPOR0bJ31GfyHThneQPEH/LA1rU71ihGkomv3DehNcnI+/LHN/3CgN76kgufz9Mv39AWUiwmTXgjdk83fDTLasRNH0p9ZpwKsZuM++X5fhucILh8rDjarLmt/2ZzimavkS5v8dZ2OA7CzLgwpdllQX1tCtevXqMmjQILN06R9//GFujnLtbVx1mozu06k1Fy9eNE0u8+bNczjnd999J8HBwXLhwoV0v2dCQoJpukm7wTUaJGzdEyNDez6S7vGPxjwvSUnJUqbJQClat4/0HT1HPh3X1fySVtof/J/hn0mnx+tJjcol0z1HydsKyzeTe5oadNH7+kipRv3l2Klz5txAZtu087D0HP6ZPNX7PXnlzS+lZPFCsmB6X8mb5/qllNs/Wsf0/Wzcdui6YzNGPSfHVr0tu398w/RS9B71+XVjdkSNlJNrJpjy4IyvVsqn/5dxcIKs5Ss+4uvj5ibem6vI8qDi2gU9PvvsMylXrpwphfwbDRx0nq1Om0lLnz/55JMZromuN21JexMXvakLrDt68qwMHv+1fDDyOQkKzJXumDemRZn073fvvSjLPhkgPds+YHoqtHasPvhyhcRfuiJ9n2ua4ffRZs+XRn8uz7SqLcs+7i9R7/eRgFx+0nHghyYoATLTkrW7TMPlzgPHTUniqZemmhLeY01qOozT/weebHZXhlmK/074Whq2+588+8r7phT4Rt/HrxvTsts78kCHcfLym3OkxzON5ImmtTLtfcE9lD+yeaOm3tc9b9685rFmHnSFMN2naW8runTpInXr1jXlE32tLkW6YMECWbJkSYavGTx4sMOCHpqpILCwbuueI/LHmQvSsP3/7Pu0PLF280GZ/tVK+WXeENN8tnbOq1KpbDF7Wnfd5oPmr7AJg9vIyl/3yS/bD5kMRFqNOo6Vp5rfJVOHdTBjQ4Jzy4jej9mPvz+io9z50BD5dcdhubuq481vgMwUF39ZDhw5bc+22Tz6QHXJHRQgc+ZvTPd1tp6L/b+fMuXAH2e8LONmLJRTsf9kSI8cjzVfdx08LmEF88nAbi1NrwWQ02R5UNGoUSOZOnWqeay3V50yZYq5eYqu+mXFPffcY+77/vHHH5vSiWY69EYrtsU/0uPsnvX4dw3uriBrvvivw75eIz6TO0oVlZc6PGg615XvNSu8+Pn5SGrKXxmGN/s9Ka92/6d35uSf5+WJF9+TmaM7meZOdflKYjrn8LU3ygE3U3DuACl9W2H58k/H303tHq0rP67cLrHn4v/1HLZ/zwEB/k7HBObK8l/NyIgnUg0+4rWy/F+uljC03GEzY8YMU5KYPn26NG36V2o8bao77brkabMV7733ngkqtPTRqVMn03eBzJEvOEgql/traVebPLkDpGBosNmvMzP0r7m+Y74wszp0//zl2+TnDXtlzoTuZnxEeEGH19vq1KVvC5Pb/m6Ga1qvikz54mcZO/1HeaJZLTPbZOR735s1AiLTrGUBZIYRL7WWhau2m1kZxcJCZVC3VpKsTcc//ZNBKF2isFk75ek+f/1hlNaDdStLWKEQ2bzrd/Nvt1KZYjK892OyfstBc07V5akGcvTkGdl3+K8bN9WtUU56tW1syoPInlinIpsHFdfSYEBLH5cvX7YvQaqlDdsNTbRR81rt2rWTAQMGmCVHd+3aJR07drzp141/6MyMue/0kOHv/p+0efl9uXgpwczRnzKsvTS9r4pLGZHpozrKpE+WyKRPF5sUs5Y85k36j3kMZKbbiuSXGaM62Reu2rA1Wh7sNN4hI9HukTpy/PQ5WbZ+z3Wvv5xwVTo+VldG931cAnL5mybjqOVbZMKsxQ6/77TZWRdz0xLioaN/mv9vPvqGNSqQM2XpMt26ToXeWtXWaKnlj3fffdeUQ/QOavfdd5+ULVtW7r33XnnjjTdk37598sorr8jevXvl0KFDUqrUX2ly1bZtWzML5IEHHpAff/zRpetgmW7cClimG97sZi3TvXTLEcmbz73zx1+Ik8bVb/fKZbqzfPbHwoULTYOlbnoL1l9++UW++uoradiwoeTKlUu++OIL2bNnj0RGRsr//vc/GTVqVLrn0TurJSYmyvPPM90QAJA5mP2Rjcsfs2bNMpszmq24doXN9JIrx44dM9NQH330UY9fJwAAyIE9Fa66dOmS6bl488035YUXXjD3gwcAIFMw+yN7lz/cNXbsWKlYsaJZkVPXnwAAILNnf7j7n7fK8UHFsGHDzDRTvW+IbREtAAAy8y6l7m7eKscHFQAAIHvI8T0VAADcLLRUOEdQAQCAVUQVTlH+AAAAHkGmAgAAi7j3h3MEFQAAWOSJ2Rs+3htTUP4AAACeQaYCAACL6NN0jqACAACriCqcovwBAAA8gkwFAAAWMfvDOYIKAAAsYvaHcwQVAABYREuFc/RUAAAAjyBTAQCAVaQqnCJTAQCAi42a7v7nimHDhomPj4/DVrFiRfvxK1euSM+ePaVQoUKSN29eeeKJJ+TUqVMO5zhy5Ii0atVK8uTJI0WKFJH+/ftLUlKSw5jly5dLzZo1JTAwUMqVKyezZs0SVxFUAACQzVWpUkVOnDhh31avXm0/1rdvX/nhhx/kq6++khUrVsjx48fl8ccftx9PTk42AUViYqKsXbtWPv74YxMwDB061D7m0KFDZkyjRo1ky5Yt0qdPH+nSpYv89NNPLl0n5Q8AALJg9kdcXJzDfs0Q6JYef39/CQ8Pv27/+fPn5cMPP5TPP/9cHnjgAbPvo48+kkqVKsn69evl3nvvlUWLFsmuXbtkyZIlUrRoUalevbqMHDlSBg4caLIgAQEBMm3aNCldurSMHz/enENfr4HLhAkTpFmzZpbfG5kKAABcbKlwd1MRERESGhpq38aMGSMZ2b9/vxQvXlzKlCkjbdu2NeUMtWnTJrl69ao0adLEPlZLI7fffrusW7fOPNevVatWNQGFjQYKGtTs3LnTPibtOWxjbOewikwFAABZICYmRkJCQuzPM8pS1K5d25QrKlSoYEofw4cPl/r168uOHTvk5MmTJtOQP39+h9doAKHHlH5NG1DYjtuOORujgcfly5cld+7clt4TQQUAAFkw+yMkJMQhqMhIixYt7I8jIyNNkFGyZEmZO3eu5Q/7m4XyBwAA2Xj2x7U0K1G+fHk5cOCA6bPQBsxz5845jNHZH7YeDP167WwQ2/N/G6NBjyuBC0EFAAA5SHx8vBw8eFCKFSsmtWrVkly5csnSpUvtx/fu3Wt6LurUqWOe69ft27fL6dOn7WMWL15sAobKlSvbx6Q9h22M7RxWEVQAAODi7A93N1f069fPTBU9fPiwmRLaunVr8fPzkzZt2pgGz86dO8vLL78sP//8s2nc7NSpkwkGdOaHatq0qQke2rdvL1u3bjXTRF977TWztoWtj6N79+4SHR0tAwYMkD179siUKVNMeUWnq7qCngoAALLxgppHjx41AURsbKyEhYVJvXr1zHRRfax02qevr69Z9CohIcHM2tCgwEYDkKioKOnRo4cJNoKDg6Vjx44yYsQI+xidTjp//nwTREycOFFKlCghM2bMcGk6qXlvqampqXKL0+5WjfZOxZ631DQD5EQF7u6V1ZcAZJrU5ERJ2D7drNuQGb/HbZ8Tm/afkLz53Dt//IU4qXVHsUy71qxE+QMAAHgE5Q8AACzyxOwNHy++oxhBBQAAVnlgmW7x3piC8gcAAPAMMhUAAGTj2R85CUEFAABWEVU4RfkDAAB4BJkKAAAsYvaHcwQVAABYdCPLbF/L7dkj2RjlDwAA4BFkKgAAsIg+TecIKgAAsIqowimCCgAALKJR0zl6KgAAgEeQqQAAwCJT/XB39od4L4IKAAAsoqXCOcofAADAI8hUAABgEYtfOUdQAQCAZRRAnKH8AQAAPIJMBQAAFlH+cI6gAgAAiyh+OEf5AwAAeASZCgAALKL84RxBBQAAFnHvD+cIKgAAsIqmCqfoqQAAAB5BpgIAAItIVDhHUAEAgEU0ajpH+QMAAHgEQQUAAC7O/nD3vxv15ptvio+Pj/Tp08e+7+DBg9K6dWsJCwuTkJAQefrpp+XUqVMOrztz5oy0bdvWHM+fP7907txZ4uPjHcZs27ZN6tevL0FBQRIRESFjx451+foIKgAAcLWpwt3tBvzyyy/y/vvvS2RkpH3fxYsXpWnTpibQWLZsmaxZs0YSExPl4YcflpSUFPs4DSh27twpixcvlqioKFm5cqV069bNfjwuLs6cp2TJkrJp0yYZN26cDBs2TD744AOXrpGeCgAAsrn4+HgTGEyfPl1GjRpl369BxOHDh2Xz5s0mC6E+/vhjKVCggAkymjRpIrt375aFCxeaoOSuu+4yYyZPniwtW7aUt956S4oXLy6zZ882wcjMmTMlICBAqlSpIlu2bJG3337bIfj4N2QqAADIgkRFXFycw5aQkJDh9+3Zs6e0atXKBAlp6Ws0SxEYGGjfp+ULX19fWb16tXm+bt06U/KwBRRKz6NjNmzYYB/ToEEDE1DYNGvWTPbu3Stnz561/PMhqAAAwMXZH+5uSvsWQkND7duYMWMkPXPmzJHffvst3eP33nuvBAcHy8CBA+XSpUumHNKvXz9JTk6WEydOmDEnT56UIkWKOLzO399fChYsaI7ZxhQtWtRhjO25bYwVBBUAAGSBmJgYOX/+vH0bPHhwumNeeuklU57QDMS1tDnzq6++kh9++EHy5s1rgpNz585JzZo1TSbiZqOnAgAAy9y/94f8/XrtgbD1QWREmyZPnz5tggQbzUJoo+W7775ryh/aYKkzQP7880+TgdBSR3h4uJQpU8aM18d6jrSSkpLMjBA9Zhtz7YwR23PbGCvIVAAAkAXlDysaN24s27dvN02Ttk17I7RpUx/7+fnZxxYuXNgEFNqgqUHEI488YvbXqVPHZC80QLHRMTo7pHbt2vYxGqhcvXrVPkZnilSoUME0fVpFpgIAgGwqX758cueddzrs0x6KQoUK2fd/9NFHUqlSJVMK0YZLLZf07dvXBARKjzVv3ly6du0q06ZNM4FDr1695JlnnjEzP9Szzz4rw4cPN+tXaH/Gjh07ZOLEiTJhwgSXrpegAgCAHGzv3r2mH0PLGaVKlZJXX33VBBVpaU+GBhKa+dBeiyeeeEImTZpkP669GIsWLTKzTGrVqmWyHkOHDnVpOqnySU1NTZVbnE7l0R/oqdjz/1rfAnKqAnf3yupLADJNanKiJGyfbhoeM+P3uO1z4veTZ9w+f1xcnJQML5hp15qVyFQAAGCRu8tsK/cbPbMvGjUBAIBHkKkAAMAibn3uHEEFAAAWuXE/MDsvjikofwAAAM8gUwEAgFWkKpwiqAAAwCJmfzhH+QMAAHgEmQoAACxi9odzBBUAAFhES4VzBBUAAFhFVOEUPRUAAMAjyFQAAGARsz+cI6gAAMAiGjWdI6jQW+b+fff3C3FxWX0pQKbeGhrw9n/ftt/nmUVvW54dzpFdEVRoMHHhgvlarnREVl8KAMDN3+ehoaEeP29AQICEh4fLHR76nAgPDzfn9DY+qZkd1uUAKSkpcvz4ccmXL5/4eHNeKpvQKD0iIkJiYmIkJCQkqy8H8Dj+jd98+lGmAUXx4sXF1zdz5iBcuXJFEhM9k/ELCAiQoKAg8TZkKnQKjK+vlChRIqsv45ajv2z5hQtvxr/xmyszMhRpaRDgjYGAJzGlFAAAeARBBQAA8AiCCtx0gYGB8vrrr5uvgDfi3zhuVTRqAgAAjyBTAQAAPIKgAgAAeARBBQAA8AiCCmQLhw8fNguPbdmyxTxfvny5eX7u3LmsvjQAgEUEFQBgwXPPPWcCXdtWqFAhad68uWzbti2rLw3INggqAMAiDSJOnDhhtqVLl4q/v7889NBDWX1ZQLZBUAGPmjdvnlStWlVy585t/pJr0qSJXLx40RybMWOGVKpUySxzW7FiRZkyZUpWXy7gEl13Qm8EpVv16tVl0KBB5v4ef/zxR7olOy3n6T4t7+n/B7pkt/4/ktZ3330nwcHB9hsbAjkZ9/6Ax+hfb23atJGxY8dK69atzS/JVatWmRv9zJ49W4YOHSrvvvuu1KhRQzZv3ixdu3Y1v0w7duyY1ZcOuCw+Pl4+++wzKVeunAmg/43+W3/mmWfko48+kieffNK+3/Zcb2gI5HQEFfBoUJGUlCSPP/64lCxZ0uzTrIXS1QXHjx9vjqnSpUvLrl275P333yeoQI4RFRUlefPmNY8181CsWDGzz+pdMbt06SJ169Y1/6/oa0+fPi0LFiyQJUuWZPKVAzcH5Q94TLVq1aRx48YmkHjqqadk+vTpcvbsWfPL9+DBg9K5c2fzC9m2jRo1yuwHcopGjRqZkoZuGzdulGbNmkmLFi3k999/t/T6e+65R6pUqSIff/yxea6ZDg3AGzRokMlXDtwcBBXwGD8/P1m8eLH8+OOPUrlyZZk8ebJUqFBBduzYYY5rkGH7hayb7l+/fn1WXzZgmZYwtNyh29133236hDRo1n/btmxF2jsfXL16Nd1sxaxZs+ylj06dOpm+C8AbEFTAo/SX43333SfDhw83fRMBAQGyZs0aKV68uERHR9t/Ids2LYMAOfnfuwYTly9flrCwMLNPSxs2tnVX0mrXrp3JbEyaNMmUACn/wZvQUwGP2bBhg5lm17RpUylSpIh5rl3xOuNDg4zevXtLaGiomZaXkJAgv/76qymPvPzyy1l96YAl+u/25MmT5rH+29XGY23YfPjhh02QHBERIcOGDZM33nhD9u3bZ/qIrlWgQAHTW9S/f3/z/0qJEiWy4J0AmYOgAh6j0+VWrlwp77zzjsTFxZlasf5S1ZqzypMnj4wbN878MtU0svZe9OnTJ6svG7Bs4cKFpsFS6WwNnRr91VdfScOGDc2+L774Qnr06CGRkZGmPKJ9Q9pfdC3tL/r888/l+eefv+nvAchM3PocAG6yTz/9VPr27SvHjx83JULAW5CpAICb5NKlS6bn4s0335QXXniBgAJeh0ZNALhJdGE4LZnoipyDBw/O6ssBPI7yBwAA8AgyFQAAwCMIKgAAgEcQVAAAAI8gqAAAAB5BUAEAADyCoALIJp577jl57LHH7M91lcasWHF0+fLl5p4W586dy3CMHv/uu+8sn1OXrq5evbpb13X48GHzfdO7nwaA7IGgAviXD3r9INNNFyrS+zuMGDFCkpKSMv17f/PNNzJy5EiPBQIAkNlYURP4F3oDNL1Ftd5MasGCBdKzZ0/JlStXuosXJSYmemyVxIIFC3rkPABws5CpAP5FYGCgWQFRb5CmN4tq0qSJfP/99w4lC70rpd7evUKFCmZ/TEyMPP3005I/f34THDz66KMmfW+TnJxs7s6qxwsVKiQDBgyQa9ehu7b8oUHNwIEDzZ0w9Zo0a/Lhhx+a8zZq1Mh+B0zNWOh1qZSUFBkzZoy5xXzu3LmlWrVqMm/ePIfvo4FS+fLlzXE9T9rrtEqvS8+hN40rU6aMDBkyRK5evXrduPfff99cv47Tn8/58+cdjs+YMcPc1TYoKMisPDllyhSXrwVA1iGoAFykH76akbDR273v3btXFi9eLFFRUebDtFmzZuYulqtWrZI1a9ZI3rx5TcbD9jq9e+usWbNk5syZsnr1ajlz5ox8++23Tr9vhw4dzF0wJ02aJLt37zYf0Hpe/ZD++uuvzRi9Dr23xMSJE81zDSg++eQTmTZtmuzcudPcxKpdu3ayYsUKe/Cjt+HWW3drr0KXLl1k0KBBLv9M9L3q+9m1a5f53tOnT5cJEyY4jDlw4IDMnTtXfvjhB3O3z82bN8t//vMf+/HZs2fL0KFDTYCm72/06NEmOPn4449dvh4AWUSX6QaQvo4dO6Y++uij5nFKSkrq4sWLUwMDA1P79etnP160aNHUhIQE+2s+/fTT1AoVKpjxNno8d+7cqT/99JN5XqxYsdSxY8faj1+9ejW1RIkS9u+l7r///tSXXnrJPN67d6+mMcz3T8/PP/9sjp89e9a+78qVK6l58uRJXbt2rcPYzp07p7Zp08Y8Hjx4cGrlypUdjg8cOPC6c11Lj3/77bcZHh83blxqrVq17M9ff/31VD8/v9SjR4/a9/3444+pvr6+qSdOnDDPy5Ytm/r55587nGfkyJGpderUMY8PHTpkvu/mzZsz/L4AshY9FcC/0OyDZgQ0A6HlhGeffdbMZrCpWrWqQx/F1q1bzV/l+td7WleuXJGDBw+alL9mE2rXrm0/5u/vL3fdddd1JRAbzSL4+fnJ/fffb/m69Rr0rpgPPvigw37NltSoUcM81oxA2utQderUEVd9+eWXJoOi7y8+Pt40soaEhDiMuf322+W2225z+D7689Tsiv6s9LWdO3eWrl272sfoeUJDQ12+HgBZg6AC+BfaZzB16lQTOGjfhAYAaQUHBzs81w/VWrVqmXT+tcLCwm645OIqvQ41f/58hw9zpT0ZnrJu3Tpp27atDB8+3JR9NAiYM2eOKfG4eq1aNrk2yNFgCkDOQFAB/AsNGrQp0qqaNWuav9yLFCly3V/rNsWKFZMNGzZIgwYN7H+Rb9q0ybw2PZoN0b/qtRdCG0WvZcuUaAOoTeXKlU3wcOTIkQwzHNoUaWs6tVm/fr24Yu3ataaJ9dVXX7Xv+/33368bp9dx/PhxE5jZvo+vr69pbi1atKjZHx0dbQIUADkTjZqAh+mHYuHChc2MD23UPHTokFlHonfv3nL06FEz5qWXXpI333zTLCC1Z88e07DobI2JUqVKSceOHeX55583r7GdUxsflX6o66wPLdX88ccf5i9/LSn069fPNGdqs6OWF3777TeZPHmyvfmxe/fusn//funfv78pQ3z++eem4dIVd9xxhwkYNDuh30PLIOk1neqMDn0PWh7Sn4v+PHQGiM6sUZrp0MZSff2+fftk+/btZirv22+/7dL1AMg6BBWAh+l0yZUrV5oeAp1ZodkA7RXQngpb5uKVV16R9u3bmw9Z7S3QAKB169ZOz6slmCeffNIEIDrdUnsPLl68aI5peUM/lHXmhv7V36tXL7NfF8/SGRT6Ya3XoTNQtByiU0yVXqPOHNFARaeb6iwRnXXhikceecQELvo9ddVMzVzo97yWZnv059GyZUtp2rSpREZGOkwZ1ZknOqVUAwnNzGh2RQMc27UCyP58tFszqy8CAADkfGQqAACARxBUAAAAjyCoAAAAHkFQAQAAPIKgAgAAeARBBQAA8AiCCgAA4BEEFQAAwCMIKgAAgEcQVAAAAI8gqAAAAOIJ/x8ozO0i9POssAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"sell (0)\", \"Buy (1)\"]))\n",
    "\n",
    "# Optional: Confusion Matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred), display_labels=[\"sell\", \"Buy\"])\n",
    "disp.plot(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:06:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5382\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    sell (0)       0.54      0.51      0.53     10455\n",
      "     Buy (1)       0.54      0.56      0.55     10581\n",
      "\n",
      "    accuracy                           0.54     21036\n",
      "   macro avg       0.54      0.54      0.54     21036\n",
      "weighted avg       0.54      0.54      0.54     21036\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x13d19c200>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "model2.fit(\n",
    "    X_train, y_train,\n",
    ")\n",
    "\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"sell (0)\", \"Buy (1)\"]))\n",
    "\n",
    "# Optional: Confusion Matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred), display_labels=[\"sell\", \"Buy\"])\n",
    "disp.plot(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(model, max_num_features=30)\n",
    "plot_importance(model2, max_num_features=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-03 16:43:26,503] A new study created in memory with name: no-name-16a66897-737c-4cae-8426-7037209b645f\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:27,007] Trial 0 finished with value: 0.5339804561436844 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.01365265437481088, 'subsample': 0.7378648225138321, 'colsample_bytree': 0.9598796818797372, 'min_child_weight': 5, 'gamma': 0.10692744236612584}. Best is trial 0 with value: 0.5339804561436844.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:27,533] Trial 1 finished with value: 0.5316796252096289 and parameters: {'n_estimators': 84, 'max_depth': 4, 'learning_rate': 0.019587530612439744, 'subsample': 0.7039621529193958, 'colsample_bytree': 0.9961475743243771, 'min_child_weight': 7, 'gamma': 0.11659061791402114}. Best is trial 0 with value: 0.5339804561436844.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:28,051] Trial 2 finished with value: 0.5327824869864198 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011149821630977583, 'subsample': 0.7660811347995675, 'colsample_bytree': 0.9391532227178584, 'min_child_weight': 7, 'gamma': 0.16897360240720863}. Best is trial 0 with value: 0.5339804561436844.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:28,552] Trial 3 finished with value: 0.5326303868792476 and parameters: {'n_estimators': 82, 'max_depth': 4, 'learning_rate': 0.019772723350937316, 'subsample': 0.7464076524251428, 'colsample_bytree': 0.9344517623851244, 'min_child_weight': 3, 'gamma': 0.1351230518875793}. Best is trial 0 with value: 0.5339804561436844.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:29,133] Trial 4 finished with value: 0.5324497425443925 and parameters: {'n_estimators': 105, 'max_depth': 4, 'learning_rate': 0.012104352728846177, 'subsample': 0.7921226721779816, 'colsample_bytree': 0.9718673647465301, 'min_child_weight': 7, 'gamma': 0.16231999414997705}. Best is trial 0 with value: 0.5339804561436844.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:29,790] Trial 5 finished with value: 0.5311091626214254 and parameters: {'n_estimators': 98, 'max_depth': 5, 'learning_rate': 0.019936697758035107, 'subsample': 0.6663950586895058, 'colsample_bytree': 0.9032844712787901, 'min_child_weight': 4, 'gamma': 0.16583529650781778}. Best is trial 0 with value: 0.5339804561436844.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:30,282] Trial 6 finished with value: 0.5325448143994964 and parameters: {'n_estimators': 83, 'max_depth': 4, 'learning_rate': 0.020183008239954486, 'subsample': 0.7175674960772053, 'colsample_bytree': 0.9959484874269227, 'min_child_weight': 3, 'gamma': 0.04689166701026917}. Best is trial 0 with value: 0.5339804561436844.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:30,775] Trial 7 finished with value: 0.5340280007491894 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.013574708842475771, 'subsample': 0.6106942023982915, 'colsample_bytree': 0.925113311238597, 'min_child_weight': 7, 'gamma': 0.03038379271885896}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:31,308] Trial 8 finished with value: 0.5327254633445141 and parameters: {'n_estimators': 94, 'max_depth': 4, 'learning_rate': 0.01635474666076147, 'subsample': 0.756554215760139, 'colsample_bytree': 0.9703640333173064, 'min_child_weight': 4, 'gamma': 0.1521290230902963}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:31,720] Trial 9 finished with value: 0.5335145894638663 and parameters: {'n_estimators': 80, 'max_depth': 3, 'learning_rate': 0.011061480439826996, 'subsample': 0.6375881356589003, 'colsample_bytree': 0.9807835280089098, 'min_child_weight': 3, 'gamma': 0.050942052299306845}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:32,472] Trial 10 finished with value: 0.5293027181881285 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.02978862988077821, 'subsample': 0.6094311943633653, 'colsample_bytree': 0.9119591527024589, 'min_child_weight': 6, 'gamma': 0.009297089335969889}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:32,978] Trial 11 finished with value: 0.5330867349295051 and parameters: {'n_estimators': 108, 'max_depth': 3, 'learning_rate': 0.014776037371043103, 'subsample': 0.6667088640858183, 'colsample_bytree': 0.9525029749090762, 'min_child_weight': 5, 'gamma': 0.08261524280425196}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:33,430] Trial 12 finished with value: 0.5339044131409351 and parameters: {'n_estimators': 91, 'max_depth': 3, 'learning_rate': 0.013858487986602214, 'subsample': 0.6033595612292565, 'colsample_bytree': 0.9247873402678128, 'min_child_weight': 5, 'gamma': 0.08383262667901348}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:33,938] Trial 13 finished with value: 0.5335431082000629 and parameters: {'n_estimators': 109, 'max_depth': 3, 'learning_rate': 0.013043749443280173, 'subsample': 0.725505503865705, 'colsample_bytree': 0.9503417917817049, 'min_child_weight': 6, 'gamma': 0.0003100466728790906}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:34,470] Trial 14 finished with value: 0.5330677361787993 and parameters: {'n_estimators': 116, 'max_depth': 3, 'learning_rate': 0.016280281226106606, 'subsample': 0.6775941351051133, 'colsample_bytree': 0.9602338458239882, 'min_child_weight': 6, 'gamma': 0.048944038154511274}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:34,914] Trial 15 finished with value: 0.5319743490994328 and parameters: {'n_estimators': 91, 'max_depth': 3, 'learning_rate': 0.02467820632365339, 'subsample': 0.6389609279398847, 'colsample_bytree': 0.9198125149056412, 'min_child_weight': 4, 'gamma': 0.10574221908696028}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:35,484] Trial 16 finished with value: 0.5335050762580261 and parameters: {'n_estimators': 104, 'max_depth': 3, 'learning_rate': 0.010031863499254463, 'subsample': 0.7949820688501436, 'colsample_bytree': 0.9380813034234154, 'min_child_weight': 5, 'gamma': 0.075356030186293}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:36,223] Trial 17 finished with value: 0.5315370139015544 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.015287941710377829, 'subsample': 0.6855716558955547, 'colsample_bytree': 0.9290921121793856, 'min_child_weight': 6, 'gamma': 0.0253202339008209}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:36,799] Trial 18 finished with value: 0.5333149393274688 and parameters: {'n_estimators': 95, 'max_depth': 4, 'learning_rate': 0.012952931994867356, 'subsample': 0.6389733793578859, 'colsample_bytree': 0.9644926648570618, 'min_child_weight': 6, 'gamma': 0.18670386126800054}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:37,285] Trial 19 finished with value: 0.5334385350713039 and parameters: {'n_estimators': 103, 'max_depth': 3, 'learning_rate': 0.017111156913606398, 'subsample': 0.7369217977239576, 'colsample_bytree': 0.9428493735650765, 'min_child_weight': 4, 'gamma': 0.13290718751236733}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:37,724] Trial 20 finished with value: 0.5338378407678196 and parameters: {'n_estimators': 88, 'max_depth': 3, 'learning_rate': 0.011728093633332947, 'subsample': 0.7719337987946997, 'colsample_bytree': 0.9824940902834164, 'min_child_weight': 5, 'gamma': 0.06254767543750622}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:38,184] Trial 21 finished with value: 0.5335716361565844 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.014010348172081485, 'subsample': 0.6126576282720637, 'colsample_bytree': 0.9243754978829453, 'min_child_weight': 5, 'gamma': 0.08968667528064263}. Best is trial 7 with value: 0.5340280007491894.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:38,630] Trial 22 finished with value: 0.5343607733945637 and parameters: {'n_estimators': 89, 'max_depth': 3, 'learning_rate': 0.013568893108385865, 'subsample': 0.620347412416812, 'colsample_bytree': 0.9148067659842375, 'min_child_weight': 5, 'gamma': 0.028314649879953364}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:39,115] Trial 23 finished with value: 0.5336381955127706 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.012694802462889274, 'subsample': 0.6284002115188614, 'colsample_bytree': 0.9013957365820569, 'min_child_weight': 5, 'gamma': 0.0331845270100404}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:39,558] Trial 24 finished with value: 0.5340089925069728 and parameters: {'n_estimators': 87, 'max_depth': 3, 'learning_rate': 0.014779244031552577, 'subsample': 0.6482906626657329, 'colsample_bytree': 0.9147541414721421, 'min_child_weight': 4, 'gamma': 0.031167536378276003}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:40,075] Trial 25 finished with value: 0.533647711972843 and parameters: {'n_estimators': 86, 'max_depth': 4, 'learning_rate': 0.015171713904569461, 'subsample': 0.6556757064072494, 'colsample_bytree': 0.9140974765082488, 'min_child_weight': 4, 'gamma': 0.026199121053362015}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:40,524] Trial 26 finished with value: 0.5334765526404811 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.017919194685779266, 'subsample': 0.6195633559086727, 'colsample_bytree': 0.9090611725800359, 'min_child_weight': 4, 'gamma': 0.017061855624537495}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:40,962] Trial 27 finished with value: 0.5334765531828531 and parameters: {'n_estimators': 87, 'max_depth': 3, 'learning_rate': 0.010523585497641662, 'subsample': 0.6509977221199494, 'colsample_bytree': 0.918784162219368, 'min_child_weight': 7, 'gamma': 0.03725448574735888}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:41,513] Trial 28 finished with value: 0.5331343090942869 and parameters: {'n_estimators': 94, 'max_depth': 4, 'learning_rate': 0.012084114301647936, 'subsample': 0.6204997932811873, 'colsample_bytree': 0.9311762673769196, 'min_child_weight': 3, 'gamma': 0.06512996342990769}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:41,978] Trial 29 finished with value: 0.5330011735683808 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.01415978168575118, 'subsample': 0.6517122211780676, 'colsample_bytree': 0.9066671151979918, 'min_child_weight': 6, 'gamma': 0.013010528125529042}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:42,452] Trial 30 finished with value: 0.5328490558341169 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.017456530378989442, 'subsample': 0.6897558749973134, 'colsample_bytree': 0.916713693499162, 'min_child_weight': 4, 'gamma': 0.05752760943684898}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:42,876] Trial 31 finished with value: 0.5333814813277492 and parameters: {'n_estimators': 84, 'max_depth': 3, 'learning_rate': 0.013386070735339548, 'subsample': 0.7030335282450646, 'colsample_bytree': 0.9579625081786606, 'min_child_weight': 5, 'gamma': 0.11014243336151174}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:43,343] Trial 32 finished with value: 0.5334765670133406 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.015394124651267539, 'subsample': 0.6309895257076588, 'colsample_bytree': 0.9413521608940234, 'min_child_weight': 5, 'gamma': 0.12825702013252327}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:43,812] Trial 33 finished with value: 0.5333909877539388 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.011465855337785184, 'subsample': 0.6233345111310828, 'colsample_bytree': 0.9254563308092097, 'min_child_weight': 7, 'gamma': 0.10034280091248926}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:44,413] Trial 34 finished with value: 0.5333434577924793 and parameters: {'n_estimators': 107, 'max_depth': 4, 'learning_rate': 0.014523831536601532, 'subsample': 0.6031447972432293, 'colsample_bytree': 0.9460322774583237, 'min_child_weight': 7, 'gamma': 0.11796933113305401}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:44,978] Trial 35 finished with value: 0.5330202024207357 and parameters: {'n_estimators': 101, 'max_depth': 4, 'learning_rate': 0.018521915682407547, 'subsample': 0.7225080270244209, 'colsample_bytree': 0.9100346818165201, 'min_child_weight': 4, 'gamma': 0.03969672585289602}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:45,406] Trial 36 finished with value: 0.5329916657862612 and parameters: {'n_estimators': 84, 'max_depth': 3, 'learning_rate': 0.012502226838348665, 'subsample': 0.7133495941289194, 'colsample_bytree': 0.9340337327205052, 'min_child_weight': 5, 'gamma': 0.07295174904874757}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:45,851] Trial 37 finished with value: 0.5326969356591787 and parameters: {'n_estimators': 92, 'max_depth': 3, 'learning_rate': 0.021430332099199617, 'subsample': 0.7467799145470243, 'colsample_bytree': 0.9063297484860473, 'min_child_weight': 6, 'gamma': 0.14700655058460124}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:46,408] Trial 38 finished with value: 0.532164514775709 and parameters: {'n_estimators': 99, 'max_depth': 4, 'learning_rate': 0.01640835393525831, 'subsample': 0.7748166996221624, 'colsample_bytree': 0.9200013144757185, 'min_child_weight': 3, 'gamma': 0.023780741413525396}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:46,826] Trial 39 finished with value: 0.5336762225734587 and parameters: {'n_estimators': 81, 'max_depth': 3, 'learning_rate': 0.010921223763008296, 'subsample': 0.6610902045003836, 'colsample_bytree': 0.9713431538783834, 'min_child_weight': 4, 'gamma': 0.007899977159720031}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:47,551] Trial 40 finished with value: 0.5316321090786568 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.01336307745604172, 'subsample': 0.6460031298560576, 'colsample_bytree': 0.9831688671135838, 'min_child_weight': 5, 'gamma': 0.04476087223920762}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:47,985] Trial 41 finished with value: 0.5339804751267064 and parameters: {'n_estimators': 88, 'max_depth': 3, 'learning_rate': 0.013785906527285308, 'subsample': 0.6024441713595077, 'colsample_bytree': 0.9242914258180749, 'min_child_weight': 5, 'gamma': 0.08791878078743881}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:48,422] Trial 42 finished with value: 0.5342752112198815 and parameters: {'n_estimators': 88, 'max_depth': 3, 'learning_rate': 0.01569834034615733, 'subsample': 0.6007926309062299, 'colsample_bytree': 0.9146722976380438, 'min_child_weight': 5, 'gamma': 0.056144391712689326}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:48,863] Trial 43 finished with value: 0.534094555495213 and parameters: {'n_estimators': 88, 'max_depth': 3, 'learning_rate': 0.015337574263182205, 'subsample': 0.6122371875741551, 'colsample_bytree': 0.913996278368205, 'min_child_weight': 5, 'gamma': 0.05349533125592117}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:49,287] Trial 44 finished with value: 0.5340755431852061 and parameters: {'n_estimators': 85, 'max_depth': 3, 'learning_rate': 0.016251255282708658, 'subsample': 0.6141725812517415, 'colsample_bytree': 0.9001511954869318, 'min_child_weight': 6, 'gamma': 0.05455987866140649}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:49,722] Trial 45 finished with value: 0.5337998280799908 and parameters: {'n_estimators': 85, 'max_depth': 3, 'learning_rate': 0.015924568844691896, 'subsample': 0.6139030313102228, 'colsample_bytree': 0.9027455578791499, 'min_child_weight': 7, 'gamma': 0.05845157934303588}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:50,146] Trial 46 finished with value: 0.533552619778787 and parameters: {'n_estimators': 83, 'max_depth': 3, 'learning_rate': 0.02155500166392881, 'subsample': 0.6115408427099073, 'colsample_bytree': 0.9003100071982792, 'min_child_weight': 6, 'gamma': 0.0512586292956729}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:50,555] Trial 47 finished with value: 0.5340755540326472 and parameters: {'n_estimators': 80, 'max_depth': 3, 'learning_rate': 0.018754922469961164, 'subsample': 0.6319978371525237, 'colsample_bytree': 0.9121739059192724, 'min_child_weight': 6, 'gamma': 0.07075070780304901}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:50,989] Trial 48 finished with value: 0.5339424418287395 and parameters: {'n_estimators': 80, 'max_depth': 3, 'learning_rate': 0.018955640285837173, 'subsample': 0.6313057619723786, 'colsample_bytree': 0.9054349575378243, 'min_child_weight': 6, 'gamma': 0.06705568922470255}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:51,403] Trial 49 finished with value: 0.5340470136015684 and parameters: {'n_estimators': 81, 'max_depth': 3, 'learning_rate': 0.016781310884219018, 'subsample': 0.6203991893681573, 'colsample_bytree': 0.9116037035553295, 'min_child_weight': 6, 'gamma': 0.05324067859086511}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:51,893] Trial 50 finished with value: 0.5327825070541858 and parameters: {'n_estimators': 82, 'max_depth': 4, 'learning_rate': 0.020548133002322316, 'subsample': 0.6022406907724033, 'colsample_bytree': 0.9208470775407287, 'min_child_weight': 6, 'gamma': 0.07622285141035959}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:52,307] Trial 51 finished with value: 0.5341420960329275 and parameters: {'n_estimators': 81, 'max_depth': 3, 'learning_rate': 0.01691293557638043, 'subsample': 0.6221624400315018, 'colsample_bytree': 0.9108454402561268, 'min_child_weight': 6, 'gamma': 0.055227474212107754}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:52,749] Trial 52 finished with value: 0.533714248549403 and parameters: {'n_estimators': 89, 'max_depth': 3, 'learning_rate': 0.017975798213995794, 'subsample': 0.6374518274868567, 'colsample_bytree': 0.9090030514956572, 'min_child_weight': 6, 'gamma': 0.0426006744941794}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:53,185] Trial 53 finished with value: 0.5333909969742637 and parameters: {'n_estimators': 85, 'max_depth': 3, 'learning_rate': 0.015811303212456794, 'subsample': 0.6263201838781121, 'colsample_bytree': 0.9162991887236022, 'min_child_weight': 5, 'gamma': 0.06778705613398582}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:53,607] Trial 54 finished with value: 0.5336477008542159 and parameters: {'n_estimators': 82, 'max_depth': 3, 'learning_rate': 0.019150942622892842, 'subsample': 0.6135231829450549, 'colsample_bytree': 0.9060040338210893, 'min_child_weight': 5, 'gamma': 0.05608826644327498}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:54,058] Trial 55 finished with value: 0.5329916752777721 and parameters: {'n_estimators': 92, 'max_depth': 3, 'learning_rate': 0.016845293524914928, 'subsample': 0.6367614352463403, 'colsample_bytree': 0.9126250034931229, 'min_child_weight': 6, 'gamma': 0.09112932520446468}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:54,491] Trial 56 finished with value: 0.533124777990169 and parameters: {'n_estimators': 86, 'max_depth': 3, 'learning_rate': 0.018080928506895112, 'subsample': 0.6705930429831856, 'colsample_bytree': 0.900076463038228, 'min_child_weight': 5, 'gamma': 0.07864880457896987}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:54,906] Trial 57 finished with value: 0.5333814799718191 and parameters: {'n_estimators': 80, 'max_depth': 3, 'learning_rate': 0.02327919366884956, 'subsample': 0.6087412066559017, 'colsample_bytree': 0.999122827509372, 'min_child_weight': 6, 'gamma': 0.044783683094140055}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:55,490] Trial 58 finished with value: 0.5297495655071028 and parameters: {'n_estimators': 84, 'max_depth': 5, 'learning_rate': 0.029620140457714602, 'subsample': 0.6178691561849714, 'colsample_bytree': 0.9223267345078453, 'min_child_weight': 5, 'gamma': 0.018942185865283158}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:55,915] Trial 59 finished with value: 0.5341325776745528 and parameters: {'n_estimators': 83, 'max_depth': 3, 'learning_rate': 0.014710605986097301, 'subsample': 0.6071985987218325, 'colsample_bytree': 0.9301484352153658, 'min_child_weight': 6, 'gamma': 0.0350736869391768}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:56,342] Trial 60 finished with value: 0.5340470268896839 and parameters: {'n_estimators': 83, 'max_depth': 3, 'learning_rate': 0.014605980997020238, 'subsample': 0.6002928419581052, 'colsample_bytree': 0.9289927121538529, 'min_child_weight': 5, 'gamma': 0.03583259159736868}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:56,780] Trial 61 finished with value: 0.533932935131364 and parameters: {'n_estimators': 86, 'max_depth': 3, 'learning_rate': 0.01555705148885807, 'subsample': 0.6074111164481486, 'colsample_bytree': 0.9166636231979135, 'min_child_weight': 6, 'gamma': 0.04952830487601899}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:57,245] Trial 62 finished with value: 0.5334670641125694 and parameters: {'n_estimators': 88, 'max_depth': 3, 'learning_rate': 0.01721010295754726, 'subsample': 0.6271549193173593, 'colsample_bytree': 0.9099778082035592, 'min_child_weight': 6, 'gamma': 0.06149368026854103}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:57,664] Trial 63 finished with value: 0.5339994868943413 and parameters: {'n_estimators': 82, 'max_depth': 3, 'learning_rate': 0.016147931669460994, 'subsample': 0.6424120618629058, 'colsample_bytree': 0.9137246341684531, 'min_child_weight': 6, 'gamma': 0.028798299979495186}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:58,095] Trial 64 finished with value: 0.5341611221734219 and parameters: {'n_estimators': 85, 'max_depth': 3, 'learning_rate': 0.015094032754174149, 'subsample': 0.6153084015465965, 'colsample_bytree': 0.9045118225579407, 'min_child_weight': 6, 'gamma': 0.0033296528692686317}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:58,540] Trial 65 finished with value: 0.5335526273719958 and parameters: {'n_estimators': 87, 'max_depth': 3, 'learning_rate': 0.015077229789596452, 'subsample': 0.6318193897860545, 'colsample_bytree': 0.9358636379666663, 'min_child_weight': 5, 'gamma': 0.0025335712208586656}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:58,962] Trial 66 finished with value: 0.533733261672968 and parameters: {'n_estimators': 81, 'max_depth': 3, 'learning_rate': 0.014162032804950557, 'subsample': 0.6073197148213622, 'colsample_bytree': 0.9276523253194189, 'min_child_weight': 7, 'gamma': 0.017786173845388158}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:59,411] Trial 67 finished with value: 0.5339519406617202 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.014697360906353311, 'subsample': 0.6225450828065842, 'colsample_bytree': 0.9182923688661486, 'min_child_weight': 6, 'gamma': 0.009824856953159052}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:43:59,839] Trial 68 finished with value: 0.5342276668855627 and parameters: {'n_estimators': 83, 'max_depth': 3, 'learning_rate': 0.013099040233550076, 'subsample': 0.6165994332528595, 'colsample_bytree': 0.903872326737693, 'min_child_weight': 5, 'gamma': 0.022191173603260683}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:00,300] Trial 69 finished with value: 0.5341135783814751 and parameters: {'n_estimators': 92, 'max_depth': 3, 'learning_rate': 0.012269448165842429, 'subsample': 0.6174266406581786, 'colsample_bytree': 0.9042528702468114, 'min_child_weight': 5, 'gamma': 0.0012013909646041987}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:00,762] Trial 70 finished with value: 0.5340280045457937 and parameters: {'n_estimators': 93, 'max_depth': 3, 'learning_rate': 0.01246303143777735, 'subsample': 0.6180111289546751, 'colsample_bytree': 0.904550046167447, 'min_child_weight': 5, 'gamma': 0.002014007470081597}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:01,216] Trial 71 finished with value: 0.5338093328790642 and parameters: {'n_estimators': 89, 'max_depth': 3, 'learning_rate': 0.013147910488699533, 'subsample': 0.6074416153350949, 'colsample_bytree': 0.9079686597957541, 'min_child_weight': 5, 'gamma': 0.022644948249664107}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:01,661] Trial 72 finished with value: 0.5341421041685084 and parameters: {'n_estimators': 87, 'max_depth': 3, 'learning_rate': 0.012029359233746154, 'subsample': 0.6001880375677332, 'colsample_bytree': 0.9034357058094673, 'min_child_weight': 5, 'gamma': 0.01188056677240028}. Best is trial 22 with value: 0.5343607733945637.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:02,103] Trial 73 finished with value: 0.5344178200872817 and parameters: {'n_estimators': 86, 'max_depth': 3, 'learning_rate': 0.011824506659275763, 'subsample': 0.6011067721524439, 'colsample_bytree': 0.9034693332627993, 'min_child_weight': 5, 'gamma': 0.01370953132468708}. Best is trial 73 with value: 0.5344178200872817.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:02,540] Trial 74 finished with value: 0.5343227381982946 and parameters: {'n_estimators': 85, 'max_depth': 3, 'learning_rate': 0.011838469047592143, 'subsample': 0.6054490056890658, 'colsample_bytree': 0.9037614739481635, 'min_child_weight': 5, 'gamma': 0.01179630436961106}. Best is trial 73 with value: 0.5344178200872817.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:02,986] Trial 75 finished with value: 0.5345604368190765 and parameters: {'n_estimators': 86, 'max_depth': 3, 'learning_rate': 0.01169139106252839, 'subsample': 0.6011125068184024, 'colsample_bytree': 0.9031599361911451, 'min_child_weight': 5, 'gamma': 0.014147911905906425}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:03,449] Trial 76 finished with value: 0.5341230875195249 and parameters: {'n_estimators': 86, 'max_depth': 3, 'learning_rate': 0.011579133331670922, 'subsample': 0.6005454461306943, 'colsample_bytree': 0.9033500228109037, 'min_child_weight': 5, 'gamma': 0.010973069396965168}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:03,895] Trial 77 finished with value: 0.5341611172920734 and parameters: {'n_estimators': 87, 'max_depth': 3, 'learning_rate': 0.010709037871999156, 'subsample': 0.6051095310896899, 'colsample_bytree': 0.9078802003756745, 'min_child_weight': 5, 'gamma': 0.013779138549712652}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:04,347] Trial 78 finished with value: 0.5342752022707425 and parameters: {'n_estimators': 89, 'max_depth': 3, 'learning_rate': 0.010362244613255332, 'subsample': 0.6064434334024675, 'colsample_bytree': 0.9086263298825125, 'min_child_weight': 5, 'gamma': 0.019651073623091993}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:04,798] Trial 79 finished with value: 0.5344653560148337 and parameters: {'n_estimators': 89, 'max_depth': 3, 'learning_rate': 0.01128014830455293, 'subsample': 0.6143131707215416, 'colsample_bytree': 0.907259115449892, 'min_child_weight': 5, 'gamma': 0.022047268260419334}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:05,341] Trial 80 finished with value: 0.5330297023384605 and parameters: {'n_estimators': 91, 'max_depth': 4, 'learning_rate': 0.011188714346483875, 'subsample': 0.6249744440946089, 'colsample_bytree': 0.9075227191536501, 'min_child_weight': 5, 'gamma': 0.02320132497678617}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:05,778] Trial 81 finished with value: 0.5339139160417062 and parameters: {'n_estimators': 85, 'max_depth': 3, 'learning_rate': 0.010132211388649993, 'subsample': 0.614489036583989, 'colsample_bytree': 0.9028533776860709, 'min_child_weight': 5, 'gamma': 0.006007195897684167}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:06,227] Trial 82 finished with value: 0.5341706210064027 and parameters: {'n_estimators': 89, 'max_depth': 3, 'learning_rate': 0.010387881335418656, 'subsample': 0.6094406159335023, 'colsample_bytree': 0.9091480760453072, 'min_child_weight': 5, 'gamma': 0.01870323761543977}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:06,677] Trial 83 finished with value: 0.5342752003724405 and parameters: {'n_estimators': 89, 'max_depth': 3, 'learning_rate': 0.010442907772102378, 'subsample': 0.6088149048820514, 'colsample_bytree': 0.9100343339606747, 'min_child_weight': 5, 'gamma': 0.02949800642338736}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:07,128] Trial 84 finished with value: 0.5341230853500366 and parameters: {'n_estimators': 89, 'max_depth': 3, 'learning_rate': 0.011350027276807352, 'subsample': 0.6038512112852311, 'colsample_bytree': 0.9143167855119054, 'min_child_weight': 5, 'gamma': 0.02982980811044459}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:07,589] Trial 85 finished with value: 0.5339804642792653 and parameters: {'n_estimators': 91, 'max_depth': 3, 'learning_rate': 0.011774368650179539, 'subsample': 0.6101564943378283, 'colsample_bytree': 0.9063500905725961, 'min_child_weight': 4, 'gamma': 0.02756863620215059}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:08,140] Trial 86 finished with value: 0.5335145902774244 and parameters: {'n_estimators': 120, 'max_depth': 3, 'learning_rate': 0.010927585510557433, 'subsample': 0.6932098666913767, 'colsample_bytree': 0.9162873784784179, 'min_child_weight': 5, 'gamma': 0.03969691496401261}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:08,614] Trial 87 finished with value: 0.5341325833694593 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.0104615833898583, 'subsample': 0.6198279069861058, 'colsample_bytree': 0.9015496102016223, 'min_child_weight': 5, 'gamma': 0.02116191206529716}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:09,060] Trial 88 finished with value: 0.5337427803025289 and parameters: {'n_estimators': 88, 'max_depth': 3, 'learning_rate': 0.012696852133681538, 'subsample': 0.625975385382118, 'colsample_bytree': 0.9110682885642442, 'min_child_weight': 5, 'gamma': 0.029896145461910724}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:09,543] Trial 89 finished with value: 0.5339424393880653 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.011959119193989216, 'subsample': 0.6000631510090801, 'colsample_bytree': 0.9183544799055883, 'min_child_weight': 4, 'gamma': 0.01418641937194676}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:09,997] Trial 90 finished with value: 0.5334290196959753 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.010088324547698903, 'subsample': 0.6350950480649723, 'colsample_bytree': 0.9018710395029818, 'min_child_weight': 5, 'gamma': 0.00695572785741257}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:10,449] Trial 91 finished with value: 0.5345224051482259 and parameters: {'n_estimators': 89, 'max_depth': 3, 'learning_rate': 0.010761141117027275, 'subsample': 0.6092278523658129, 'colsample_bytree': 0.909160483113846, 'min_child_weight': 5, 'gamma': 0.0175158139724252}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:10,910] Trial 92 finished with value: 0.5342656977428552 and parameters: {'n_estimators': 93, 'max_depth': 3, 'learning_rate': 0.010686668069210162, 'subsample': 0.6115271081163398, 'colsample_bytree': 0.9065444296873816, 'min_child_weight': 5, 'gamma': 0.015464639915433865}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:11,372] Trial 93 finished with value: 0.5342181588322569 and parameters: {'n_estimators': 93, 'max_depth': 3, 'learning_rate': 0.010921496326949578, 'subsample': 0.6058678890222792, 'colsample_bytree': 0.9119809943344922, 'min_child_weight': 5, 'gamma': 0.0323841840076839}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:11,823] Trial 94 finished with value: 0.5340945614613056 and parameters: {'n_estimators': 88, 'max_depth': 3, 'learning_rate': 0.01069586143325352, 'subsample': 0.6114207040480755, 'colsample_bytree': 0.9072052997396804, 'min_child_weight': 5, 'gamma': 0.015417653634532742}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:12,284] Trial 95 finished with value: 0.533942437218577 and parameters: {'n_estimators': 91, 'max_depth': 3, 'learning_rate': 0.011414308402107838, 'subsample': 0.6054946855449006, 'colsample_bytree': 0.9149720079396463, 'min_child_weight': 5, 'gamma': 0.19147218397029886}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:12,749] Trial 96 finished with value: 0.5344558509445743 and parameters: {'n_estimators': 93, 'max_depth': 3, 'learning_rate': 0.011090310345625812, 'subsample': 0.6114754736915361, 'colsample_bytree': 0.9216092975572326, 'min_child_weight': 5, 'gamma': 0.007239427095451799}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:13,194] Trial 97 finished with value: 0.5328680665170078 and parameters: {'n_estimators': 86, 'max_depth': 3, 'learning_rate': 0.011123092366920153, 'subsample': 0.622645972064588, 'colsample_bytree': 0.920633577079841, 'min_child_weight': 5, 'gamma': 0.0064106995139271376}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:13,650] Trial 98 finished with value: 0.5341991489629242 and parameters: {'n_estimators': 89, 'max_depth': 3, 'learning_rate': 0.010267646348487603, 'subsample': 0.6163680885809618, 'colsample_bytree': 0.9096952888531246, 'min_child_weight': 5, 'gamma': 0.025254640108673045}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:14,324] Trial 99 finished with value: 0.5316796341587677 and parameters: {'n_estimators': 97, 'max_depth': 5, 'learning_rate': 0.01176228907970779, 'subsample': 0.6293978475687596, 'colsample_bytree': 0.9123555285745526, 'min_child_weight': 5, 'gamma': 0.037984279899973036}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:14,765] Trial 100 finished with value: 0.5340945644443519 and parameters: {'n_estimators': 87, 'max_depth': 3, 'learning_rate': 0.01118902560307786, 'subsample': 0.6051468619942608, 'colsample_bytree': 0.9175227214561508, 'min_child_weight': 5, 'gamma': 0.00930327004312801}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:15,235] Trial 101 finished with value: 0.5344368402616834 and parameters: {'n_estimators': 93, 'max_depth': 3, 'learning_rate': 0.0106169195210946, 'subsample': 0.6120293282382747, 'colsample_bytree': 0.9059222318294788, 'min_child_weight': 5, 'gamma': 0.013831371495463346}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:15,704] Trial 102 finished with value: 0.5341706212775887 and parameters: {'n_estimators': 92, 'max_depth': 3, 'learning_rate': 0.010631854164394841, 'subsample': 0.6120057676463486, 'colsample_bytree': 0.9094228716616687, 'min_child_weight': 5, 'gamma': 0.019374459605461795}. Best is trial 75 with value: 0.5345604368190765.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:16,197] Trial 103 finished with value: 0.5345699462283124 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.011573766132532052, 'subsample': 0.6048662858510958, 'colsample_bytree': 0.9561817922415351, 'min_child_weight': 5, 'gamma': 0.027034719826063452}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:16,669] Trial 104 finished with value: 0.5336667020455957 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012777589467286968, 'subsample': 0.7884728355487967, 'colsample_bytree': 0.9565169278280181, 'min_child_weight': 5, 'gamma': 0.025007416622179618}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:17,140] Trial 105 finished with value: 0.5341135748560567 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.011529045413221431, 'subsample': 0.6035365810969394, 'colsample_bytree': 0.9510260958145786, 'min_child_weight': 5, 'gamma': 0.012527764819451614}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:17,673] Trial 106 finished with value: 0.5338568655523839 and parameters: {'n_estimators': 112, 'max_depth': 3, 'learning_rate': 0.01228840774691651, 'subsample': 0.6194639301381959, 'colsample_bytree': 0.9547531795287647, 'min_child_weight': 5, 'gamma': 9.364720880498251e-05}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:18,148] Trial 107 finished with value: 0.5339899685359667 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010910780288219754, 'subsample': 0.7354572780884008, 'colsample_bytree': 0.9629848304107449, 'min_child_weight': 5, 'gamma': 0.005968759797082347}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:18,635] Trial 108 finished with value: 0.5340945614613056 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.01186729532348988, 'subsample': 0.6138003565600514, 'colsample_bytree': 0.9474462629078934, 'min_child_weight': 5, 'gamma': 0.016235387995312503}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:19,098] Trial 109 finished with value: 0.5337332736051531 and parameters: {'n_estimators': 91, 'max_depth': 3, 'learning_rate': 0.013535743097232369, 'subsample': 0.600313368214143, 'colsample_bytree': 0.9756264142269773, 'min_child_weight': 4, 'gamma': 0.019203620922163493}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:19,535] Trial 110 finished with value: 0.5333339464849413 and parameters: {'n_estimators': 84, 'max_depth': 3, 'learning_rate': 0.012255246408436764, 'subsample': 0.6222144169668182, 'colsample_bytree': 0.9605004716647468, 'min_child_weight': 5, 'gamma': 0.03337624832699851}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:19,985] Trial 111 finished with value: 0.5344178200872817 and parameters: {'n_estimators': 88, 'max_depth': 3, 'learning_rate': 0.010379680255290983, 'subsample': 0.6089251166419827, 'colsample_bytree': 0.9231383131423209, 'min_child_weight': 5, 'gamma': 0.026928977113585262}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:20,447] Trial 112 finished with value: 0.5343512675107461 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.01025266652954412, 'subsample': 0.6090585129087348, 'colsample_bytree': 0.9268273718429566, 'min_child_weight': 5, 'gamma': 0.04103572136385237}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:20,915] Trial 113 finished with value: 0.5340470279744278 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.01129333914297899, 'subsample': 0.6098028039677837, 'colsample_bytree': 0.922595435604852, 'min_child_weight': 5, 'gamma': 0.04270588139338966}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:21,365] Trial 114 finished with value: 0.5335811555997032 and parameters: {'n_estimators': 88, 'max_depth': 3, 'learning_rate': 0.010970514715652992, 'subsample': 0.6159252131037721, 'colsample_bytree': 0.9270938931326737, 'min_child_weight': 5, 'gamma': 0.0471002027914593}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:21,822] Trial 115 finished with value: 0.5335716470040255 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.010115885805895848, 'subsample': 0.6024535348438668, 'colsample_bytree': 0.9228622934859076, 'min_child_weight': 5, 'gamma': 0.03525299149330936}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:22,309] Trial 116 finished with value: 0.5345319197099963 and parameters: {'n_estimators': 93, 'max_depth': 3, 'learning_rate': 0.011668664743764736, 'subsample': 0.6100861810800056, 'colsample_bytree': 0.9327635345828704, 'min_child_weight': 5, 'gamma': 0.023815627797932237}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:22,783] Trial 117 finished with value: 0.5337712982251671 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011568765876415506, 'subsample': 0.6269499791466149, 'colsample_bytree': 0.9391377600842685, 'min_child_weight': 5, 'gamma': 0.025288567610561613}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:23,250] Trial 118 finished with value: 0.5336762193192265 and parameters: {'n_estimators': 93, 'max_depth': 3, 'learning_rate': 0.010761034161512207, 'subsample': 0.618954115700254, 'colsample_bytree': 0.9317918219210167, 'min_child_weight': 5, 'gamma': 0.17844547114676507}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:23,722] Trial 119 finished with value: 0.5342466827209879 and parameters: {'n_estimators': 92, 'max_depth': 3, 'learning_rate': 0.011223646387170955, 'subsample': 0.6133094412002701, 'colsample_bytree': 0.933774570033277, 'min_child_weight': 5, 'gamma': 0.01223814229514204}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:24,162] Trial 120 finished with value: 0.5337237517213601 and parameters: {'n_estimators': 86, 'max_depth': 3, 'learning_rate': 0.012089938934778319, 'subsample': 0.7089455579769416, 'colsample_bytree': 0.9270233481757709, 'min_child_weight': 5, 'gamma': 0.027200770295428695}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:24,610] Trial 121 finished with value: 0.534512896010176 and parameters: {'n_estimators': 87, 'max_depth': 3, 'learning_rate': 0.011643158266221913, 'subsample': 0.6089302036094171, 'colsample_bytree': 0.9203810026070276, 'min_child_weight': 5, 'gamma': 0.0089888714592108}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:25,061] Trial 122 finished with value: 0.5340945641731659 and parameters: {'n_estimators': 87, 'max_depth': 3, 'learning_rate': 0.011768531184766238, 'subsample': 0.6093465880728551, 'colsample_bytree': 0.9252863497826378, 'min_child_weight': 5, 'gamma': 0.010160625587742365}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:25,516] Trial 123 finished with value: 0.534332254115995 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.011575031207461521, 'subsample': 0.6050956465640027, 'colsample_bytree': 0.9195338487473851, 'min_child_weight': 5, 'gamma': 0.0046295363718495495}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:25,980] Trial 124 finished with value: 0.5337903151453367 and parameters: {'n_estimators': 92, 'max_depth': 3, 'learning_rate': 0.011439201400995337, 'subsample': 0.615797165322715, 'colsample_bytree': 0.9206848350779364, 'min_child_weight': 5, 'gamma': 0.005913535850663959}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:26,439] Trial 125 finished with value: 0.5341611105124228 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.010013611623308376, 'subsample': 0.6084913835882212, 'colsample_bytree': 0.9236891735158772, 'min_child_weight': 5, 'gamma': 0.01587110369469092}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:26,913] Trial 126 finished with value: 0.5335240910087075 and parameters: {'n_estimators': 91, 'max_depth': 3, 'learning_rate': 0.012507502130806706, 'subsample': 0.621675658831442, 'colsample_bytree': 0.9213224838030691, 'min_child_weight': 5, 'gamma': 0.02342296169735323}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:27,379] Trial 127 finished with value: 0.5337522772372072 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.010297126664063967, 'subsample': 0.6810668755826094, 'colsample_bytree': 0.9264252865152809, 'min_child_weight': 5, 'gamma': 0.0037972052397313803}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:27,833] Trial 128 finished with value: 0.5337427748788081 and parameters: {'n_estimators': 88, 'max_depth': 3, 'learning_rate': 0.01099087912115181, 'subsample': 0.6043879873855235, 'colsample_bytree': 0.9191834677109054, 'min_child_weight': 5, 'gamma': 0.008345553410047656}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:28,320] Trial 129 finished with value: 0.5335145886503083 and parameters: {'n_estimators': 93, 'max_depth': 3, 'learning_rate': 0.010585082464929776, 'subsample': 0.6129250921523611, 'colsample_bytree': 0.9289882959394955, 'min_child_weight': 5, 'gamma': 0.02050278156234996}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:28,865] Trial 130 finished with value: 0.533381499768399 and parameters: {'n_estimators': 91, 'max_depth': 4, 'learning_rate': 0.011592847894635027, 'subsample': 0.6000696844722717, 'colsample_bytree': 0.9160887665409169, 'min_child_weight': 5, 'gamma': 0.03954934974635192}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:29,312] Trial 131 finished with value: 0.5341611170208874 and parameters: {'n_estimators': 86, 'max_depth': 3, 'learning_rate': 0.011955319548448438, 'subsample': 0.6067439280166493, 'colsample_bytree': 0.901640356243372, 'min_child_weight': 5, 'gamma': 0.011890202600817374}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:29,757] Trial 132 finished with value: 0.5340470192964749 and parameters: {'n_estimators': 85, 'max_depth': 3, 'learning_rate': 0.01118141418618993, 'subsample': 0.6047320179035834, 'colsample_bytree': 0.9244484974889544, 'min_child_weight': 5, 'gamma': 0.016412300986593124}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:30,195] Trial 133 finished with value: 0.533742773522878 and parameters: {'n_estimators': 84, 'max_depth': 3, 'learning_rate': 0.01083441087663563, 'subsample': 0.6113412749621504, 'colsample_bytree': 0.9056522372901142, 'min_child_weight': 5, 'gamma': 0.029832893018778235}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:30,819] Trial 134 finished with value: 0.5341611115971668 and parameters: {'n_estimators': 87, 'max_depth': 3, 'learning_rate': 0.01054605015577135, 'subsample': 0.6174213206128647, 'colsample_bytree': 0.9538508287350924, 'min_child_weight': 5, 'gamma': 0.0003927497827745721}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:31,273] Trial 135 finished with value: 0.5343227528423401 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.01244972760468214, 'subsample': 0.6083319221295368, 'colsample_bytree': 0.9432850211887798, 'min_child_weight': 5, 'gamma': 0.023063075973159042}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:31,735] Trial 136 finished with value: 0.5344653636080424 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.012511383974785899, 'subsample': 0.6091545325943782, 'colsample_bytree': 0.9425793374937348, 'min_child_weight': 5, 'gamma': 0.02174137053809016}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:32,193] Trial 137 finished with value: 0.5333909953471475 and parameters: {'n_estimators': 89, 'max_depth': 3, 'learning_rate': 0.012911614706856147, 'subsample': 0.6232825349439396, 'colsample_bytree': 0.932291088554752, 'min_child_weight': 5, 'gamma': 0.15219772346700736}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:32,660] Trial 138 finished with value: 0.5343797919418493 and parameters: {'n_estimators': 92, 'max_depth': 3, 'learning_rate': 0.011327923470768083, 'subsample': 0.6150650980065284, 'colsample_bytree': 0.9408693304556411, 'min_child_weight': 5, 'gamma': 0.019039372937077685}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:33,124] Trial 139 finished with value: 0.5337522842880441 and parameters: {'n_estimators': 92, 'max_depth': 3, 'learning_rate': 0.01130725107641521, 'subsample': 0.6179718696510623, 'colsample_bytree': 0.9430139629660166, 'min_child_weight': 5, 'gamma': 0.03266936596390309}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:33,592] Trial 140 finished with value: 0.5332578769059612 and parameters: {'n_estimators': 91, 'max_depth': 3, 'learning_rate': 0.011030994134668464, 'subsample': 0.6339447866694338, 'colsample_bytree': 0.9369688024857098, 'min_child_weight': 5, 'gamma': 0.020103872205726958}. Best is trial 103 with value: 0.5345699462283124.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:34,067] Trial 141 finished with value: 0.5350643433053263 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011635345481127188, 'subsample': 0.612362081489218, 'colsample_bytree': 0.9413591184659863, 'min_child_weight': 5, 'gamma': 0.026564379763230256}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:34,565] Trial 142 finished with value: 0.5339709619208661 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.012143018014652006, 'subsample': 0.6135974215204065, 'colsample_bytree': 0.9469653382842427, 'min_child_weight': 5, 'gamma': 0.027361597440588588}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:35,051] Trial 143 finished with value: 0.5343512723920947 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011667658830374392, 'subsample': 0.6106245470133637, 'colsample_bytree': 0.9422805637610789, 'min_child_weight': 5, 'gamma': 0.01672768594355243}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:35,547] Trial 144 finished with value: 0.5335145894638664 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011718723795913353, 'subsample': 0.627719857996197, 'colsample_bytree': 0.9444538065338581, 'min_child_weight': 5, 'gamma': 0.0173638272539976}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:36,020] Trial 145 finished with value: 0.5332959172547648 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.011356388225897594, 'subsample': 0.6209092601658939, 'colsample_bytree': 0.9372812153341077, 'min_child_weight': 5, 'gamma': 0.023798754224032735}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:36,490] Trial 146 finished with value: 0.5338758873539019 and parameters: {'n_estimators': 93, 'max_depth': 3, 'learning_rate': 0.01194298062076439, 'subsample': 0.6146299676038186, 'colsample_bytree': 0.9401915341002013, 'min_child_weight': 5, 'gamma': 0.015546296915832102}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:36,969] Trial 147 finished with value: 0.5342086507789512 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012513087225653714, 'subsample': 0.6113058717762047, 'colsample_bytree': 0.9457643099207141, 'min_child_weight': 5, 'gamma': 0.009092762204552945}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:37,460] Trial 148 finished with value: 0.5343607790894702 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011083917352633673, 'subsample': 0.6032508809391262, 'colsample_bytree': 0.9411976934023839, 'min_child_weight': 5, 'gamma': 0.02735177728400008}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:37,953] Trial 149 finished with value: 0.5339994942163641 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011116398526785257, 'subsample': 0.6034607381701156, 'colsample_bytree': 0.9495643839401381, 'min_child_weight': 5, 'gamma': 0.0310572157022188}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:38,435] Trial 150 finished with value: 0.5341135829916376 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.010850618830740568, 'subsample': 0.6035537216924922, 'colsample_bytree': 0.9379364628306512, 'min_child_weight': 5, 'gamma': 0.03700940971572898}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:38,921] Trial 151 finished with value: 0.533533597977269 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011477751591563915, 'subsample': 0.7602553315401703, 'colsample_bytree': 0.9406745511178345, 'min_child_weight': 5, 'gamma': 0.019976925772298097}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:39,403] Trial 152 finished with value: 0.5349787721815051 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.012180161306974916, 'subsample': 0.6090339415919584, 'colsample_bytree': 0.9350314062472763, 'min_child_weight': 5, 'gamma': 0.026451671079438237}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:39,882] Trial 153 finished with value: 0.5345699489401728 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.01216017122177568, 'subsample': 0.6001786029309952, 'colsample_bytree': 0.9348739526490807, 'min_child_weight': 5, 'gamma': 0.026187254524477132}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:40,372] Trial 154 finished with value: 0.53448437998584 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.012192998775799515, 'subsample': 0.6010585543647017, 'colsample_bytree': 0.933041100123788, 'min_child_weight': 5, 'gamma': 0.02785729015781927}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:40,876] Trial 155 finished with value: 0.5348266544472412 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012351659688615036, 'subsample': 0.6002636205829038, 'colsample_bytree': 0.9355133657409745, 'min_child_weight': 5, 'gamma': 0.03364070971827736}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:41,365] Trial 156 finished with value: 0.5342847203579313 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.01318622283910884, 'subsample': 0.6073722783719716, 'colsample_bytree': 0.9333430033401335, 'min_child_weight': 5, 'gamma': 0.034464224669738155}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:41,844] Trial 157 finished with value: 0.5346364952794296 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012224890662454586, 'subsample': 0.6005093736452345, 'colsample_bytree': 0.9311033170268316, 'min_child_weight': 5, 'gamma': 0.025285700182537754}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:42,346] Trial 158 finished with value: 0.534503383346708 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.012244269356898173, 'subsample': 0.6006177540612211, 'colsample_bytree': 0.9357515639855589, 'min_child_weight': 5, 'gamma': 0.022982369186188546}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:42,841] Trial 159 finished with value: 0.5343227444355733 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.012795106440464003, 'subsample': 0.6008713907272372, 'colsample_bytree': 0.9361654523241215, 'min_child_weight': 5, 'gamma': 0.023070680841136358}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:43,377] Trial 160 finished with value: 0.5347696061274071 and parameters: {'n_estimators': 104, 'max_depth': 3, 'learning_rate': 0.012294898893726402, 'subsample': 0.6002409290644803, 'colsample_bytree': 0.9342455608083128, 'min_child_weight': 5, 'gamma': 0.03458445134902301}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:43,936] Trial 161 finished with value: 0.533961450342142 and parameters: {'n_estimators': 103, 'max_depth': 3, 'learning_rate': 0.012199854483912816, 'subsample': 0.6059626166571344, 'colsample_bytree': 0.9352021147707785, 'min_child_weight': 5, 'gamma': 0.03198766936570097}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:44,511] Trial 162 finished with value: 0.5341991402849713 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.012358765531379262, 'subsample': 0.600560165857078, 'colsample_bytree': 0.9309306196197975, 'min_child_weight': 5, 'gamma': 0.02841156269248625}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:45,015] Trial 163 finished with value: 0.5344653533029735 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.01260469909186187, 'subsample': 0.6002407750708519, 'colsample_bytree': 0.9346446439246606, 'min_child_weight': 5, 'gamma': 0.024635026069215943}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:45,514] Trial 164 finished with value: 0.5344178284940485 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.01214985842794768, 'subsample': 0.6001070186074915, 'colsample_bytree': 0.9342025349596192, 'min_child_weight': 5, 'gamma': 0.0375155381565113}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:46,048] Trial 165 finished with value: 0.5340850574757904 and parameters: {'n_estimators': 104, 'max_depth': 3, 'learning_rate': 0.01295174018549955, 'subsample': 0.6055444248170074, 'colsample_bytree': 0.9295834242752457, 'min_child_weight': 5, 'gamma': 0.02508356447485842}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:46,547] Trial 166 finished with value: 0.5344748656952555 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.012533468133346978, 'subsample': 0.6002008976896778, 'colsample_bytree': 0.9326011619180676, 'min_child_weight': 5, 'gamma': 0.03398933857373102}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:47,054] Trial 167 finished with value: 0.5344938766493325 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.012589919580107368, 'subsample': 0.6001485800297246, 'colsample_bytree': 0.9385446809171567, 'min_child_weight': 5, 'gamma': 0.04443904993906152}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:47,556] Trial 168 finished with value: 0.5338853954072076 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.013417115689465284, 'subsample': 0.6051520639808085, 'colsample_bytree': 0.938056137919997, 'min_child_weight': 5, 'gamma': 0.033683918675229435}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:48,286] Trial 169 finished with value: 0.5314799780562774 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.01263388448369817, 'subsample': 0.6078017414819081, 'colsample_bytree': 0.9358894682621743, 'min_child_weight': 5, 'gamma': 0.04209080247531456}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:48,790] Trial 170 finished with value: 0.5345319148286477 and parameters: {'n_estimators': 104, 'max_depth': 3, 'learning_rate': 0.012051943038368252, 'subsample': 0.6001239049447654, 'colsample_bytree': 0.9312509068629246, 'min_child_weight': 5, 'gamma': 0.11715091242578392}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:49,304] Trial 171 finished with value: 0.5341325936745284 and parameters: {'n_estimators': 104, 'max_depth': 3, 'learning_rate': 0.012103478576173603, 'subsample': 0.6036780979673736, 'colsample_bytree': 0.9320176435397349, 'min_child_weight': 5, 'gamma': 0.11387501403027352}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:49,817] Trial 172 finished with value: 0.5342466913989409 and parameters: {'n_estimators': 105, 'max_depth': 3, 'learning_rate': 0.012369995313280943, 'subsample': 0.6000040900459717, 'colsample_bytree': 0.9390498730162223, 'min_child_weight': 5, 'gamma': 0.1337381617149444}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:50,316] Trial 173 finished with value: 0.5343988197094598 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.01183660079910942, 'subsample': 0.6074759225463742, 'colsample_bytree': 0.9325325865328689, 'min_child_weight': 5, 'gamma': 0.09419030492722053}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:50,820] Trial 174 finished with value: 0.5335431125390393 and parameters: {'n_estimators': 103, 'max_depth': 3, 'learning_rate': 0.013141933285910701, 'subsample': 0.6038556664260814, 'colsample_bytree': 0.9349520957184368, 'min_child_weight': 5, 'gamma': 0.03039806967079956}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:51,318] Trial 175 finished with value: 0.5346364955506155 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.01202740527442892, 'subsample': 0.6095380404630966, 'colsample_bytree': 0.9287022329237151, 'min_child_weight': 5, 'gamma': 0.12550785406114662}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:51,835] Trial 176 finished with value: 0.5342466859752203 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.012821570113370076, 'subsample': 0.6092070159027748, 'colsample_bytree': 0.9300484954368522, 'min_child_weight': 5, 'gamma': 0.12450688770920357}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:52,327] Trial 177 finished with value: 0.5336286852899765 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.012029380802816925, 'subsample': 0.6038497529561292, 'colsample_bytree': 0.9287321044752039, 'min_child_weight': 5, 'gamma': 0.13822317042012283}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:52,813] Trial 178 finished with value: 0.5345033852450102 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012402871011341729, 'subsample': 0.6004315094075685, 'colsample_bytree': 0.9312623632163761, 'min_child_weight': 5, 'gamma': 0.11457413518831898}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:53,313] Trial 179 finished with value: 0.5337522821185559 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.012234706249470541, 'subsample': 0.6034122328485535, 'colsample_bytree': 0.9308523223410599, 'min_child_weight': 5, 'gamma': 0.1065545495166195}. Best is trial 141 with value: 0.5350643433053263.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:53,802] Trial 180 finished with value: 0.5350738540704922 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011930138729288392, 'subsample': 0.6003957991987122, 'colsample_bytree': 0.9370057200454216, 'min_child_weight': 5, 'gamma': 0.12485879417884906}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:54,284] Trial 181 finished with value: 0.5348361578903844 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012001630835119912, 'subsample': 0.6005022505599199, 'colsample_bytree': 0.9334535717489307, 'min_child_weight': 5, 'gamma': 0.12381100666300034}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:54,774] Trial 182 finished with value: 0.5346840409696786 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011908079356895413, 'subsample': 0.6001206642835311, 'colsample_bytree': 0.9374259392196266, 'min_child_weight': 5, 'gamma': 0.12379113599827785}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:55,264] Trial 183 finished with value: 0.5347505867665633 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011909857421279967, 'subsample': 0.6067710958724047, 'colsample_bytree': 0.9367549928711701, 'min_child_weight': 5, 'gamma': 0.12311869419832532}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:55,756] Trial 184 finished with value: 0.5343893029782013 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.01186997684589929, 'subsample': 0.6064562720548713, 'colsample_bytree': 0.93633527843312, 'min_child_weight': 5, 'gamma': 0.12373560154867416}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:56,259] Trial 185 finished with value: 0.5344653625232983 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011636036347815355, 'subsample': 0.6063372992458574, 'colsample_bytree': 0.9357512448684834, 'min_child_weight': 5, 'gamma': 0.1174295201102987}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:56,780] Trial 186 finished with value: 0.5345129003491526 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011973201462167878, 'subsample': 0.6111585224392191, 'colsample_bytree': 0.9337698417444109, 'min_child_weight': 5, 'gamma': 0.1222465789429215}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:57,282] Trial 187 finished with value: 0.5341706283284254 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011937306233926642, 'subsample': 0.6110333251946205, 'colsample_bytree': 0.9335077999168622, 'min_child_weight': 5, 'gamma': 0.12204499933610052}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:57,779] Trial 188 finished with value: 0.5338568696201743 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.01180857340313226, 'subsample': 0.6109615876015057, 'colsample_bytree': 0.9305271206449546, 'min_child_weight': 5, 'gamma': 0.1295891022024175}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:58,269] Trial 189 finished with value: 0.5320409149640836 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.026480643120067468, 'subsample': 0.6069213159516822, 'colsample_bytree': 0.9287651622851316, 'min_child_weight': 5, 'gamma': 0.1206670500293602}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:58,764] Trial 190 finished with value: 0.5337142518036352 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011633309370357269, 'subsample': 0.657524867921815, 'colsample_bytree': 0.939472703865156, 'min_child_weight': 5, 'gamma': 0.12820527506452467}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:59,255] Trial 191 finished with value: 0.5342086524060674 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.012066154066400039, 'subsample': 0.6042561459313117, 'colsample_bytree': 0.9368205157057019, 'min_child_weight': 5, 'gamma': 0.10970533145477734}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:44:59,835] Trial 192 finished with value: 0.5337522986609035 and parameters: {'n_estimators': 96, 'max_depth': 4, 'learning_rate': 0.012324782209791222, 'subsample': 0.6000661805812963, 'colsample_bytree': 0.9343103853171206, 'min_child_weight': 5, 'gamma': 0.1158542561961861}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:44:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:00,334] Trial 193 finished with value: 0.5350548371503228 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011944505520565014, 'subsample': 0.6087159039810293, 'colsample_bytree': 0.9311357343656211, 'min_child_weight': 5, 'gamma': 0.13084006560344838}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:00,825] Trial 194 finished with value: 0.5338188403899978 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011705479543949855, 'subsample': 0.6162365937574092, 'colsample_bytree': 0.9310202499232546, 'min_child_weight': 5, 'gamma': 0.12744999068913965}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:01,362] Trial 195 finished with value: 0.5343417572879522 and parameters: {'n_estimators': 109, 'max_depth': 3, 'learning_rate': 0.011506346010648958, 'subsample': 0.611845961260387, 'colsample_bytree': 0.9317835483189286, 'min_child_weight': 5, 'gamma': 0.11889897068052115}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:01,866] Trial 196 finished with value: 0.5343227449779454 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.011828189872947602, 'subsample': 0.6072987555466259, 'colsample_bytree': 0.9276249918835575, 'min_child_weight': 5, 'gamma': 0.13769067836773444}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:02,364] Trial 197 finished with value: 0.5340375185651921 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.01204640733756219, 'subsample': 0.6145860648901279, 'colsample_bytree': 0.9379964780125005, 'min_child_weight': 5, 'gamma': 0.11251436517566084}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:02,850] Trial 198 finished with value: 0.5349312422200457 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011416316912710943, 'subsample': 0.6048452926094653, 'colsample_bytree': 0.9341560937947008, 'min_child_weight': 5, 'gamma': 0.10207290076734979}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:03,341] Trial 199 finished with value: 0.5347600978029153 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011578347989629428, 'subsample': 0.6093935345123336, 'colsample_bytree': 0.9338304526038409, 'min_child_weight': 5, 'gamma': 0.1304219817222724}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:03,823] Trial 200 finished with value: 0.5347315768972306 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011533155673025574, 'subsample': 0.609420715618897, 'colsample_bytree': 0.9664958917053948, 'min_child_weight': 5, 'gamma': 0.10155747985001}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:04,314] Trial 201 finished with value: 0.534550930121701 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011437815644234928, 'subsample': 0.605127820268278, 'colsample_bytree': 0.9337536195069684, 'min_child_weight': 5, 'gamma': 0.1260857624319431}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:04,800] Trial 202 finished with value: 0.5345984736424619 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011412421314411567, 'subsample': 0.6043926399468701, 'colsample_bytree': 0.934548934422185, 'min_child_weight': 5, 'gamma': 0.09711351835070348}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:05,291] Trial 203 finished with value: 0.5348836970721688 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011453711487428879, 'subsample': 0.6045313828606396, 'colsample_bytree': 0.9657734607850776, 'min_child_weight': 5, 'gamma': 0.10087501487864091}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:05,775] Trial 204 finished with value: 0.5347125672990839 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011388873247357528, 'subsample': 0.6048455202811678, 'colsample_bytree': 0.9653120978566752, 'min_child_weight': 5, 'gamma': 0.09583431943523013}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:06,265] Trial 205 finished with value: 0.5345699497537308 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011377244790235231, 'subsample': 0.6055606828670514, 'colsample_bytree': 0.9676047490603499, 'min_child_weight': 5, 'gamma': 0.09946926379284955}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:06,775] Trial 206 finished with value: 0.5344938758357743 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011439568354560597, 'subsample': 0.6046662040582091, 'colsample_bytree': 0.9669888039005589, 'min_child_weight': 5, 'gamma': 0.0955668960680782}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:07,257] Trial 207 finished with value: 0.5344938842425412 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.011312481834162549, 'subsample': 0.6047492672857818, 'colsample_bytree': 0.9657667692723552, 'min_child_weight': 5, 'gamma': 0.10181852379284834}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:07,749] Trial 208 finished with value: 0.5348076394253739 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011424806852545771, 'subsample': 0.6088482797782094, 'colsample_bytree': 0.9694986664353841, 'min_child_weight': 5, 'gamma': 0.08684715759113092}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:08,257] Trial 209 finished with value: 0.5346365004319641 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011202551633716116, 'subsample': 0.6143303558099489, 'colsample_bytree': 0.9692420492142858, 'min_child_weight': 5, 'gamma': 0.1021880185508694}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:08,742] Trial 210 finished with value: 0.5349122269269925 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011198188714447345, 'subsample': 0.618733587176099, 'colsample_bytree': 0.9746295494598696, 'min_child_weight': 5, 'gamma': 0.0847664825453161}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:09,231] Trial 211 finished with value: 0.533875879218321 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011134235579100203, 'subsample': 0.6712273116311943, 'colsample_bytree': 0.9738317104677962, 'min_child_weight': 5, 'gamma': 0.09885553062521998}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:09,721] Trial 212 finished with value: 0.5345509363589798 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011332512080943295, 'subsample': 0.6182927740090703, 'colsample_bytree': 0.969288233699658, 'min_child_weight': 5, 'gamma': 0.09206092444164274}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:10,217] Trial 213 finished with value: 0.5344938815306809 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011468410735203494, 'subsample': 0.6142021123711818, 'colsample_bytree': 0.9790976759227469, 'min_child_weight': 5, 'gamma': 0.10253283253251916}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:10,721] Trial 214 finished with value: 0.5347315812362071 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011180693814574105, 'subsample': 0.6087484154970275, 'colsample_bytree': 0.9678621744532228, 'min_child_weight': 5, 'gamma': 0.09767009405093804}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:11,218] Trial 215 finished with value: 0.5342371852439374 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011095757075809657, 'subsample': 0.6137509226343079, 'colsample_bytree': 0.9699179312067849, 'min_child_weight': 5, 'gamma': 0.0842844543866631}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:11,737] Trial 216 finished with value: 0.5346365031438244 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011224809621229976, 'subsample': 0.6088610958052378, 'colsample_bytree': 0.9674683403162074, 'min_child_weight': 5, 'gamma': 0.0973689982930004}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:12,231] Trial 217 finished with value: 0.5332103472156877 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.010963951942555335, 'subsample': 0.618507024955193, 'colsample_bytree': 0.962988632297651, 'min_child_weight': 5, 'gamma': 0.0843733448143258}. Best is trial 180 with value: 0.5350738540704922.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:12,726] Trial 218 finished with value: 0.535321061015766 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011173110821668948, 'subsample': 0.6092382929420269, 'colsample_bytree': 0.9740364743937512, 'min_child_weight': 5, 'gamma': 0.0883461961964486}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:13,222] Trial 219 finished with value: 0.5345509355454215 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011131686041625982, 'subsample': 0.6101632722455629, 'colsample_bytree': 0.9721677759920019, 'min_child_weight': 5, 'gamma': 0.08709584369551253}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:13,719] Trial 220 finished with value: 0.5342371771083565 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011731156251033084, 'subsample': 0.614999284856115, 'colsample_bytree': 0.9747353437141816, 'min_child_weight': 5, 'gamma': 0.08953612481019019}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:14,212] Trial 221 finished with value: 0.534978779774714 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011557042993675139, 'subsample': 0.6088913547256243, 'colsample_bytree': 0.977359854144346, 'min_child_weight': 5, 'gamma': 0.07919904232343286}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:14,715] Trial 222 finished with value: 0.5349502545300528 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.01161018274106323, 'subsample': 0.6094722699130795, 'colsample_bytree': 0.972058039297287, 'min_child_weight': 5, 'gamma': 0.07789325939182512}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:15,210] Trial 223 finished with value: 0.5348646893723242 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011591239281607567, 'subsample': 0.6107289137957415, 'colsample_bytree': 0.9780106249114293, 'min_child_weight': 5, 'gamma': 0.07675453596607676}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:15,711] Trial 224 finished with value: 0.5346555184368776 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011250910512072698, 'subsample': 0.6171036631644495, 'colsample_bytree': 0.9778779108634004, 'min_child_weight': 5, 'gamma': 0.07948658050551327}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:16,209] Trial 225 finished with value: 0.534313240721244 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011587848261452078, 'subsample': 0.6192989618829133, 'colsample_bytree': 0.9780576987117487, 'min_child_weight': 5, 'gamma': 0.0795156830385959}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:16,732] Trial 226 finished with value: 0.534893210549195 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011315320415481193, 'subsample': 0.6098429917196475, 'colsample_bytree': 0.984274925248408, 'min_child_weight': 5, 'gamma': 0.07786289997837875}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:17,231] Trial 227 finished with value: 0.5350073004092127 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010902641681603294, 'subsample': 0.6120251837776728, 'colsample_bytree': 0.9769960493360778, 'min_child_weight': 5, 'gamma': 0.07308110453684877}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:17,731] Trial 228 finished with value: 0.5347505957157023 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010783352188085517, 'subsample': 0.6100199566702026, 'colsample_bytree': 0.9886191274157382, 'min_child_weight': 5, 'gamma': 0.07220515741705169}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:18,234] Trial 229 finished with value: 0.5350738605789568 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.0108379242116568, 'subsample': 0.6120618110746335, 'colsample_bytree': 0.9832915207054985, 'min_child_weight': 5, 'gamma': 0.07318927694675736}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:18,733] Trial 230 finished with value: 0.5351023812134557 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010737043580216935, 'subsample': 0.612838179569944, 'colsample_bytree': 0.9855378797902756, 'min_child_weight': 3, 'gamma': 0.07056611813489554}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:19,234] Trial 231 finished with value: 0.5352164762260078 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.01080790357087718, 'subsample': 0.6126344023224359, 'colsample_bytree': 0.9864566555633567, 'min_child_weight': 4, 'gamma': 0.07305442240934362}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:19,737] Trial 232 finished with value: 0.5348741998663042 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.0107273244461437, 'subsample': 0.613080163481443, 'colsample_bytree': 0.9871152839342773, 'min_child_weight': 3, 'gamma': 0.07382383714989652}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:20,237] Trial 233 finished with value: 0.5339709665310286 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010742485682566303, 'subsample': 0.6138638041326937, 'colsample_bytree': 0.9868725852761393, 'min_child_weight': 3, 'gamma': 0.06981930409964425}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:20,741] Trial 234 finished with value: 0.5344368367362651 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010584340771197515, 'subsample': 0.620657469871287, 'colsample_bytree': 0.9873576388186287, 'min_child_weight': 3, 'gamma': 0.07371851071313519}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:21,362] Trial 235 finished with value: 0.5349502580554711 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.01080450797029801, 'subsample': 0.6127016962583897, 'colsample_bytree': 0.984266227701712, 'min_child_weight': 3, 'gamma': 0.06384222234002947}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:21,888] Trial 236 finished with value: 0.5346555197928078 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010777865875223534, 'subsample': 0.6167900890022581, 'colsample_bytree': 0.9847274752215076, 'min_child_weight': 3, 'gamma': 0.0661654508535899}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:22,389] Trial 237 finished with value: 0.5348741966120718 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010865017501715287, 'subsample': 0.612573543943322, 'colsample_bytree': 0.9914305946054567, 'min_child_weight': 3, 'gamma': 0.07509288612129493}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:22,897] Trial 238 finished with value: 0.5343227433508292 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010927301129537562, 'subsample': 0.622594548659764, 'colsample_bytree': 0.9920264729036213, 'min_child_weight': 3, 'gamma': 0.07715091620397821}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:23,398] Trial 239 finished with value: 0.5344653660487168 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010633559734569214, 'subsample': 0.6146418623252619, 'colsample_bytree': 0.9814699863940514, 'min_child_weight': 3, 'gamma': 0.07624243152406994}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:23,903] Trial 240 finished with value: 0.5348171531735862 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010507151039205269, 'subsample': 0.612157304031094, 'colsample_bytree': 0.9838487225687755, 'min_child_weight': 3, 'gamma': 0.08126014735588669}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:24,409] Trial 241 finished with value: 0.534646010925944 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010366269702449662, 'subsample': 0.611794859600902, 'colsample_bytree': 0.9837846287198054, 'min_child_weight': 3, 'gamma': 0.0815612381107986}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:24,906] Trial 242 finished with value: 0.5350928699059176 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010504018813533609, 'subsample': 0.6125160293905054, 'colsample_bytree': 0.9912119224347816, 'min_child_weight': 3, 'gamma': 0.06995823315949594}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:25,409] Trial 243 finished with value: 0.5344463466878729 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.01037502101641897, 'subsample': 0.6175887790109341, 'colsample_bytree': 0.9891597587852017, 'min_child_weight': 3, 'gamma': 0.06451866339780839}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:25,912] Trial 244 finished with value: 0.534655521962296 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.010546458736654156, 'subsample': 0.6132908937961783, 'colsample_bytree': 0.9928986620194928, 'min_child_weight': 3, 'gamma': 0.0697295554303075}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:26,406] Trial 245 finished with value: 0.5342181534085363 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.010877003059799781, 'subsample': 0.6976543713787462, 'colsample_bytree': 0.9855146507619308, 'min_child_weight': 3, 'gamma': 0.07499689201183421}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:26,947] Trial 246 finished with value: 0.5350073071888634 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010888230528909212, 'subsample': 0.6124060990542732, 'colsample_bytree': 0.976059906494824, 'min_child_weight': 3, 'gamma': 0.08378720164929597}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:27,450] Trial 247 finished with value: 0.5347220734540873 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.01090194391333856, 'subsample': 0.6198005060451219, 'colsample_bytree': 0.9802232001330998, 'min_child_weight': 3, 'gamma': 0.08490292104735457}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:27,951] Trial 248 finished with value: 0.5348646847621619 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010535204155284921, 'subsample': 0.6125834242612596, 'colsample_bytree': 0.9758620501616811, 'min_child_weight': 3, 'gamma': 0.08131280809009864}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:28,456] Trial 249 finished with value: 0.5349312414064876 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010537445570027925, 'subsample': 0.613274463454377, 'colsample_bytree': 0.9762945017475027, 'min_child_weight': 3, 'gamma': 0.07962335648136085}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:28,952] Trial 250 finished with value: 0.5343132431619182 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010660778160520273, 'subsample': 0.6161960405814654, 'colsample_bytree': 0.9767290014153991, 'min_child_weight': 3, 'gamma': 0.0719564080948829}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:29,462] Trial 251 finished with value: 0.5340280099695143 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010329534769692011, 'subsample': 0.6249072960187884, 'colsample_bytree': 0.9740361064681055, 'min_child_weight': 3, 'gamma': 0.07798439866749961}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:29,955] Trial 252 finished with value: 0.5346174837829806 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.010194877989153115, 'subsample': 0.6136787356152243, 'colsample_bytree': 0.9916039747473893, 'min_child_weight': 3, 'gamma': 0.06203422774310039}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:30,478] Trial 253 finished with value: 0.5351213967776949 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.01093349898518556, 'subsample': 0.6186072291215439, 'colsample_bytree': 0.9816370484142579, 'min_child_weight': 3, 'gamma': 0.07465406510767081}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:30,999] Trial 254 finished with value: 0.5345984684899273 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.010868765311832623, 'subsample': 0.6225058553967087, 'colsample_bytree': 0.9760874409550542, 'min_child_weight': 3, 'gamma': 0.07465131926670515}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:31,524] Trial 255 finished with value: 0.5339709535140994 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010649197169207337, 'subsample': 0.7307722789473456, 'colsample_bytree': 0.9819456983999306, 'min_child_weight': 3, 'gamma': 0.06712906829006604}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:32,123] Trial 256 finished with value: 0.5342752185419042 and parameters: {'n_estimators': 99, 'max_depth': 4, 'learning_rate': 0.010961587077172569, 'subsample': 0.6200345717428775, 'colsample_bytree': 0.980075992452632, 'min_child_weight': 3, 'gamma': 0.08126801301618022}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:32,618] Trial 257 finished with value: 0.5350738532569341 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.01058762903056581, 'subsample': 0.6179985724166025, 'colsample_bytree': 0.9943507846436789, 'min_child_weight': 3, 'gamma': 0.07050695131091578}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:33,126] Trial 258 finished with value: 0.5343227460626894 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.010466187999087473, 'subsample': 0.6246832175613258, 'colsample_bytree': 0.9977612667184315, 'min_child_weight': 3, 'gamma': 0.0710257524440268}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:33,625] Trial 259 finished with value: 0.5348171461227494 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010195278452567279, 'subsample': 0.6180042826419002, 'colsample_bytree': 0.9725265880906397, 'min_child_weight': 3, 'gamma': 0.07532978060020633}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:34,124] Trial 260 finished with value: 0.5347030603305223 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.010804747589634194, 'subsample': 0.6155401485363002, 'colsample_bytree': 0.9939133814184262, 'min_child_weight': 3, 'gamma': 0.07800467162159476}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:34,631] Trial 261 finished with value: 0.5340945484443763 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.010525954773115806, 'subsample': 0.7437337680021999, 'colsample_bytree': 0.9895189410467421, 'min_child_weight': 3, 'gamma': 0.05951735722281866}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:35,132] Trial 262 finished with value: 0.5344748703054181 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010015957019747323, 'subsample': 0.6167911553030921, 'colsample_bytree': 0.9773665597873277, 'min_child_weight': 3, 'gamma': 0.06817583014591054}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:35,636] Trial 263 finished with value: 0.5350358261962459 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010921074931433156, 'subsample': 0.6130255036430686, 'colsample_bytree': 0.9947096827158596, 'min_child_weight': 3, 'gamma': 0.08198580553346412}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:36,142] Trial 264 finished with value: 0.5346555149114594 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011018364637718056, 'subsample': 0.6206733517340456, 'colsample_bytree': 0.9856028426922232, 'min_child_weight': 4, 'gamma': 0.07338591537336943}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:36,659] Trial 265 finished with value: 0.5347410879335825 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.01097281536383037, 'subsample': 0.6120543859095245, 'colsample_bytree': 0.9948052903702211, 'min_child_weight': 3, 'gamma': 0.08357770226100514}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:37,169] Trial 266 finished with value: 0.5348266631251941 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.010728529766694118, 'subsample': 0.6167276356997476, 'colsample_bytree': 0.9913108252840506, 'min_child_weight': 4, 'gamma': 0.06429645849462033}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:37,667] Trial 267 finished with value: 0.5337047470045618 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011057039519117082, 'subsample': 0.6291913148962646, 'colsample_bytree': 0.9957973372529829, 'min_child_weight': 3, 'gamma': 0.090156339905931}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:38,169] Trial 268 finished with value: 0.5349977980508136 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011029324093940219, 'subsample': 0.6124933812643552, 'colsample_bytree': 0.9826077516282933, 'min_child_weight': 3, 'gamma': 0.07750608010578867}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:38,887] Trial 269 finished with value: 0.5325828585449045 and parameters: {'n_estimators': 99, 'max_depth': 5, 'learning_rate': 0.01073096236569957, 'subsample': 0.6133874121007745, 'colsample_bytree': 0.982571620795052, 'min_child_weight': 3, 'gamma': 0.07107044876675925}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:39,387] Trial 270 finished with value: 0.5338378535135629 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011063247411414383, 'subsample': 0.6228974961673335, 'colsample_bytree': 0.9870356327569632, 'min_child_weight': 3, 'gamma': 0.07701980011633595}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:39,899] Trial 271 finished with value: 0.5346079803398375 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.010797535818279042, 'subsample': 0.6166444307100465, 'colsample_bytree': 0.9815625640272403, 'min_child_weight': 3, 'gamma': 0.08750049477461491}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:40,415] Trial 272 finished with value: 0.5346365074828009 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.010370187345368565, 'subsample': 0.6121559618903869, 'colsample_bytree': 0.9906633325235735, 'min_child_weight': 3, 'gamma': 0.06859117245381842}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:40,918] Trial 273 finished with value: 0.5347981329991844 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011123709640949296, 'subsample': 0.6196583488904218, 'colsample_bytree': 0.9798033221917729, 'min_child_weight': 3, 'gamma': 0.08242074738515512}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:41,425] Trial 274 finished with value: 0.5347030511101973 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010831177143917962, 'subsample': 0.6085455621048045, 'colsample_bytree': 0.9839121870347488, 'min_child_weight': 3, 'gamma': 0.07288536955184581}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:41,951] Trial 275 finished with value: 0.534712568112642 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011166127775522958, 'subsample': 0.6131461116233066, 'colsample_bytree': 0.9973263950675133, 'min_child_weight': 3, 'gamma': 0.07855786196582112}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:42,449] Trial 276 finished with value: 0.5345224051482259 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.010584161872201268, 'subsample': 0.6087382380088042, 'colsample_bytree': 0.9865607607128998, 'min_child_weight': 3, 'gamma': 0.07313695983676403}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:42,954] Trial 277 finished with value: 0.5337998169613637 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010949404368047333, 'subsample': 0.6250150102738191, 'colsample_bytree': 0.9721950927375156, 'min_child_weight': 3, 'gamma': 0.08565340838992873}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:43,460] Trial 278 finished with value: 0.5349882870144617 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011232549832436507, 'subsample': 0.6178440517001275, 'colsample_bytree': 0.9885062402847853, 'min_child_weight': 3, 'gamma': 0.06758540070032794}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:43,965] Trial 279 finished with value: 0.5348551777936003 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011272357218030932, 'subsample': 0.619529927439917, 'colsample_bytree': 0.987982476287932, 'min_child_weight': 3, 'gamma': 0.06657152315253273}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:44,473] Trial 280 finished with value: 0.5335145889214944 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011169651652862357, 'subsample': 0.7168956530582528, 'colsample_bytree': 0.985009483287628, 'min_child_weight': 4, 'gamma': 0.06163934924840777}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:44,982] Trial 281 finished with value: 0.534484381612956 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.010439673117476466, 'subsample': 0.6169617589892061, 'colsample_bytree': 0.9826361343107746, 'min_child_weight': 3, 'gamma': 0.08032115734602799}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:45,516] Trial 282 finished with value: 0.5345604362767045 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.0106925702448333, 'subsample': 0.6073203093998417, 'colsample_bytree': 0.9743971282113568, 'min_child_weight': 3, 'gamma': 0.09227196145533671}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:46,022] Trial 283 finished with value: 0.5344273303100756 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011033285607108754, 'subsample': 0.6219235859911294, 'colsample_bytree': 0.9896571426795996, 'min_child_weight': 3, 'gamma': 0.06963093212808642}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:46,515] Trial 284 finished with value: 0.5343512702226064 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.01023712518253566, 'subsample': 0.6141635250245715, 'colsample_bytree': 0.9819464508651635, 'min_child_weight': 3, 'gamma': 0.06522757336535297}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:47,016] Trial 285 finished with value: 0.5348646855757199 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011362722341421992, 'subsample': 0.6097739851111703, 'colsample_bytree': 0.9998833744879874, 'min_child_weight': 3, 'gamma': 0.1450379455240461}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:47,531] Trial 286 finished with value: 0.533429015356999 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010668804517842261, 'subsample': 0.6430069022298848, 'colsample_bytree': 0.9788318315800506, 'min_child_weight': 3, 'gamma': 0.07902527348928565}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:48,027] Trial 287 finished with value: 0.5342466748565932 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011257977019531162, 'subsample': 0.6277186969759053, 'colsample_bytree': 0.9839267262726994, 'min_child_weight': 3, 'gamma': 0.08306313157395982}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:48,537] Trial 288 finished with value: 0.5340565346718034 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010967498893538066, 'subsample': 0.6158176575039461, 'colsample_bytree': 0.976427403211064, 'min_child_weight': 3, 'gamma': 0.06997829457670346}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:49,060] Trial 289 finished with value: 0.5335145797011693 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010473872549629181, 'subsample': 0.7777064419056385, 'colsample_bytree': 0.9867382191067878, 'min_child_weight': 3, 'gamma': 0.08862698479535247}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:49,563] Trial 290 finished with value: 0.5323927029025112 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.019503334747338598, 'subsample': 0.6078893917043023, 'colsample_bytree': 0.9795981155232286, 'min_child_weight': 3, 'gamma': 0.16113174168841488}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:50,064] Trial 291 finished with value: 0.5346174818846785 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010809234098534164, 'subsample': 0.6183464565477901, 'colsample_bytree': 0.9889988192927601, 'min_child_weight': 3, 'gamma': 0.07379976978885704}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:50,668] Trial 292 finished with value: 0.5337142721425873 and parameters: {'n_estimators': 99, 'max_depth': 4, 'learning_rate': 0.011260151709834514, 'subsample': 0.6116057051991364, 'colsample_bytree': 0.9741037125228612, 'min_child_weight': 3, 'gamma': 0.05625724785865724}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:51,154] Trial 293 finished with value: 0.5321264719862312 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.02338972541444362, 'subsample': 0.6143487487293049, 'colsample_bytree': 0.9853593550191473, 'min_child_weight': 3, 'gamma': 0.07693801653913392}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:51,669] Trial 294 finished with value: 0.534332254115995 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.011011753214959247, 'subsample': 0.6070123771814709, 'colsample_bytree': 0.9934273921236435, 'min_child_weight': 3, 'gamma': 0.07982091713883725}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:52,169] Trial 295 finished with value: 0.5345889544705291 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011478000944387282, 'subsample': 0.6213395346855353, 'colsample_bytree': 0.9809184375178506, 'min_child_weight': 3, 'gamma': 0.0847207325267623}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:52,696] Trial 296 finished with value: 0.5345889658603422 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.01061381723409724, 'subsample': 0.611409560667605, 'colsample_bytree': 0.9716758550768367, 'min_child_weight': 4, 'gamma': 0.06819991905265352}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:53,261] Trial 297 finished with value: 0.5344273305812616 and parameters: {'n_estimators': 116, 'max_depth': 3, 'learning_rate': 0.011052268896234431, 'subsample': 0.6062498923923416, 'colsample_bytree': 0.9769140800668787, 'min_child_weight': 3, 'gamma': 0.07327032751612435}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:53,757] Trial 298 finished with value: 0.5343607831572607 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011338456039240549, 'subsample': 0.6159938851164966, 'colsample_bytree': 0.9831567817346998, 'min_child_weight': 3, 'gamma': 0.06409087581760037}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:54,259] Trial 299 finished with value: 0.5319838541696921 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.0204324110139202, 'subsample': 0.6247666701702346, 'colsample_bytree': 0.9750290743309579, 'min_child_weight': 3, 'gamma': 0.07696370942082903}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:54,767] Trial 300 finished with value: 0.5349882870144615 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010795473451832554, 'subsample': 0.6105253170409148, 'colsample_bytree': 0.9785492705382233, 'min_child_weight': 3, 'gamma': 0.08120554075888488}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:55,258] Trial 301 finished with value: 0.534417823883886 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.010272632960753312, 'subsample': 0.6080413503814129, 'colsample_bytree': 0.9786342577678238, 'min_child_weight': 3, 'gamma': 0.0890039908896175}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:55,752] Trial 302 finished with value: 0.5349502539876806 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010949981480482646, 'subsample': 0.6102091626574885, 'colsample_bytree': 0.9806794226959619, 'min_child_weight': 7, 'gamma': 0.08364598422213586}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:56,279] Trial 303 finished with value: 0.5349122299100387 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.010892756262033376, 'subsample': 0.6187253373805549, 'colsample_bytree': 0.9808162193981014, 'min_child_weight': 4, 'gamma': 0.0831631583610716}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:56,780] Trial 304 finished with value: 0.5348266501082647 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010476279537779097, 'subsample': 0.6197531096997261, 'colsample_bytree': 0.9793306331616789, 'min_child_weight': 4, 'gamma': 0.08466676632070706}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:57,281] Trial 305 finished with value: 0.534237172227008 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.010870333292137426, 'subsample': 0.631980161353929, 'colsample_bytree': 0.9809160749774665, 'min_child_weight': 4, 'gamma': 0.08100117382784668}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:57,777] Trial 306 finished with value: 0.5348837030382615 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.010659024729744775, 'subsample': 0.6169998963478902, 'colsample_bytree': 0.9772537692438511, 'min_child_weight': 4, 'gamma': 0.08580880548626842}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:58,275] Trial 307 finished with value: 0.5340850487978375 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010013350610207947, 'subsample': 0.62447983302237, 'colsample_bytree': 0.9814086441722051, 'min_child_weight': 3, 'gamma': 0.0804471770584028}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:58,780] Trial 308 finished with value: 0.5345794529256881 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.01092344955880009, 'subsample': 0.6202525274998081, 'colsample_bytree': 0.9783359433437748, 'min_child_weight': 7, 'gamma': 0.08220993491823342}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:59,281] Trial 309 finished with value: 0.5348551772512281 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.01034130827160337, 'subsample': 0.6126096710546217, 'colsample_bytree': 0.9956105565195261, 'min_child_weight': 7, 'gamma': 0.08625673779582552}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:45:59,817] Trial 310 finished with value: 0.5345794561799203 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011102733936900434, 'subsample': 0.6170116379043264, 'colsample_bytree': 0.9751610038250529, 'min_child_weight': 4, 'gamma': 0.09020637865415038}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:45:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:00,315] Trial 311 finished with value: 0.5348171463939355 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010726915110684588, 'subsample': 0.6113911531847109, 'colsample_bytree': 0.9731718118234529, 'min_child_weight': 3, 'gamma': 0.1358204929196484}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:00,821] Trial 312 finished with value: 0.5341611213598637 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010499220152927929, 'subsample': 0.6159913591547831, 'colsample_bytree': 0.9801437775394543, 'min_child_weight': 6, 'gamma': 0.14086483702530883}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:01,325] Trial 313 finished with value: 0.5346174772745159 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010875770049575142, 'subsample': 0.6224835089977102, 'colsample_bytree': 0.9766072519529444, 'min_child_weight': 3, 'gamma': 0.05980419817040541}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:01,820] Trial 314 finished with value: 0.5346840336476558 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011128620766865155, 'subsample': 0.6070852926169901, 'colsample_bytree': 0.9830792713383509, 'min_child_weight': 3, 'gamma': 0.07071386722037051}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:02,330] Trial 315 finished with value: 0.5344558539276206 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011672792845762767, 'subsample': 0.6116554404630222, 'colsample_bytree': 0.9805300260766485, 'min_child_weight': 3, 'gamma': 0.09200438110251966}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:02,828] Trial 316 finished with value: 0.5347981321856264 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010589625687434604, 'subsample': 0.6191514110022841, 'colsample_bytree': 0.9940614069796975, 'min_child_weight': 3, 'gamma': 0.07667280631626666}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:03,357] Trial 317 finished with value: 0.5348171447668194 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.010255894184346836, 'subsample': 0.6145435092768449, 'colsample_bytree': 0.9855066823936844, 'min_child_weight': 3, 'gamma': 0.08322697881474797}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:03,852] Trial 318 finished with value: 0.5342181650695355 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.010824589998436884, 'subsample': 0.6084840774283544, 'colsample_bytree': 0.9773818451007739, 'min_child_weight': 3, 'gamma': 0.06785556995478541}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:04,359] Trial 319 finished with value: 0.5333339424171508 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.02126060514619077, 'subsample': 0.6839992364226072, 'colsample_bytree': 0.9823245400912239, 'min_child_weight': 3, 'gamma': 0.0746341379110702}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:04,867] Trial 320 finished with value: 0.5334100100978287 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011204350352235971, 'subsample': 0.6271392835028571, 'colsample_bytree': 0.9897974218991743, 'min_child_weight': 7, 'gamma': 0.07934174030184162}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:05,356] Trial 321 finished with value: 0.532231072504779 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.02776602778105091, 'subsample': 0.6052773502311697, 'colsample_bytree': 0.9976176540172194, 'min_child_weight': 3, 'gamma': 0.07185033659295977}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:05,864] Trial 322 finished with value: 0.5351023806710836 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011007181739073224, 'subsample': 0.6125524973762931, 'colsample_bytree': 0.9753524341488851, 'min_child_weight': 3, 'gamma': 0.08653223988274639}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:06,393] Trial 323 finished with value: 0.5343607804454004 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010947789722998095, 'subsample': 0.6108828449067449, 'colsample_bytree': 0.9851766450647066, 'min_child_weight': 3, 'gamma': 0.06272773173183137}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:06,907] Trial 324 finished with value: 0.534351276188699 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.010505882214444763, 'subsample': 0.6054115762778141, 'colsample_bytree': 0.9879820626634842, 'min_child_weight': 3, 'gamma': 0.09212290242504503}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:07,422] Trial 325 finished with value: 0.5345033974483814 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010752572984526905, 'subsample': 0.6142026689861144, 'colsample_bytree': 0.9785130226980765, 'min_child_weight': 3, 'gamma': 0.07561262109880948}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:07,924] Trial 326 finished with value: 0.5330677383482876 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.017584014454116306, 'subsample': 0.6092733089863328, 'colsample_bytree': 0.9827215240929639, 'min_child_weight': 3, 'gamma': 0.07074252510598132}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:08,425] Trial 327 finished with value: 0.534056530875199 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011487124774318902, 'subsample': 0.6147727156124918, 'colsample_bytree': 0.9922076624307419, 'min_child_weight': 3, 'gamma': 0.08836343927498558}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:08,939] Trial 328 finished with value: 0.5337903091792441 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011037128988112854, 'subsample': 0.6668772172233499, 'colsample_bytree': 0.9800222764456278, 'min_child_weight': 3, 'gamma': 0.051558256270991025}. Best is trial 218 with value: 0.535321061015766.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:09,441] Trial 329 finished with value: 0.5353876119651854 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011740091000547747, 'subsample': 0.6105274311500477, 'colsample_bytree': 0.9762208758572544, 'min_child_weight': 6, 'gamma': 0.08168009726574428}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:09,978] Trial 330 finished with value: 0.5345319161845778 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011644935530684233, 'subsample': 0.6071838765320852, 'colsample_bytree': 0.971339470375341, 'min_child_weight': 3, 'gamma': 0.07942369757156419}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:10,480] Trial 331 finished with value: 0.5346365050421266 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011846282373828758, 'subsample': 0.6115362790996521, 'colsample_bytree': 0.9756169682410747, 'min_child_weight': 6, 'gamma': 0.06665094535040783}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:10,988] Trial 332 finished with value: 0.5348551824037627 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011726019541698995, 'subsample': 0.605253551451137, 'colsample_bytree': 0.973764155952788, 'min_child_weight': 7, 'gamma': 0.07538718684522382}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:11,593] Trial 333 finished with value: 0.5334765746065494 and parameters: {'n_estimators': 99, 'max_depth': 4, 'learning_rate': 0.011248533440639426, 'subsample': 0.6120598289653223, 'colsample_bytree': 0.97715634362757, 'min_child_weight': 6, 'gamma': 0.08092152883087211}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:12,097] Trial 334 finished with value: 0.5347886165391119 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011368475423623516, 'subsample': 0.6048387181605858, 'colsample_bytree': 0.9754125085401992, 'min_child_weight': 7, 'gamma': 0.07106530287813789}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:12,616] Trial 335 finished with value: 0.5348361646700351 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.010229547234396504, 'subsample': 0.6092927829336539, 'colsample_bytree': 0.9731904129630898, 'min_child_weight': 6, 'gamma': 0.08591462120997599}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:13,124] Trial 336 finished with value: 0.5345794597053387 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010583888995383555, 'subsample': 0.6136236517763888, 'colsample_bytree': 0.9906577856826811, 'min_child_weight': 3, 'gamma': 0.1980905374917174}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:13,661] Trial 337 finished with value: 0.5347791136383407 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011444263527968627, 'subsample': 0.6088816476706187, 'colsample_bytree': 0.9495526090371249, 'min_child_weight': 7, 'gamma': 0.07770231066587543}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:14,161] Trial 338 finished with value: 0.5339709592090058 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.014316898210800972, 'subsample': 0.6049137657984085, 'colsample_bytree': 0.9782055559434966, 'min_child_weight': 3, 'gamma': 0.1318342965562381}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:14,673] Trial 339 finished with value: 0.534075552947903 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011055355023502314, 'subsample': 0.616169247557631, 'colsample_bytree': 0.9956536753429955, 'min_child_weight': 3, 'gamma': 0.065332533457741}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:15,383] Trial 340 finished with value: 0.5329821872922325 and parameters: {'n_estimators': 96, 'max_depth': 5, 'learning_rate': 0.011698787546179036, 'subsample': 0.610790863959033, 'colsample_bytree': 0.9873533765036774, 'min_child_weight': 3, 'gamma': 0.07332620173226422}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:15,883] Trial 341 finished with value: 0.5342942259705628 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010695659980152934, 'subsample': 0.6036648303012231, 'colsample_bytree': 0.9842211822248566, 'min_child_weight': 3, 'gamma': 0.09386407350201247}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:16,388] Trial 342 finished with value: 0.5343607820725165 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.010417184439841368, 'subsample': 0.6150123016034466, 'colsample_bytree': 0.9933186610061274, 'min_child_weight': 3, 'gamma': 0.08823523865252503}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:16,896] Trial 343 finished with value: 0.5344748751867665 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011159339920870693, 'subsample': 0.6083405853541929, 'colsample_bytree': 0.9759845439424237, 'min_child_weight': 3, 'gamma': 0.08136165347089663}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:17,419] Trial 344 finished with value: 0.5346840290374933 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010811798380567826, 'subsample': 0.6211123576804978, 'colsample_bytree': 0.9788241119884952, 'min_child_weight': 6, 'gamma': 0.06820287125913815}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:17,934] Trial 345 finished with value: 0.5347981346263005 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011483184747948577, 'subsample': 0.6109342032754221, 'colsample_bytree': 0.9830906258075884, 'min_child_weight': 3, 'gamma': 0.07583427157721036}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:18,445] Trial 346 finished with value: 0.5347030619576384 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011038039808729477, 'subsample': 0.6165017499159273, 'colsample_bytree': 0.9708242301705172, 'min_child_weight': 3, 'gamma': 0.06099265142590947}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:18,951] Trial 347 finished with value: 0.5342181656119077 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011804252750591073, 'subsample': 0.6065169560638108, 'colsample_bytree': 0.9859550729769241, 'min_child_weight': 3, 'gamma': 0.08295800152811571}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:19,474] Trial 348 finished with value: 0.5348076456626526 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.010421297704394667, 'subsample': 0.6126686315671728, 'colsample_bytree': 0.9806174186585532, 'min_child_weight': 3, 'gamma': 0.10754170845209708}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:20,064] Trial 349 finished with value: 0.5338949029181411 and parameters: {'n_estimators': 95, 'max_depth': 4, 'learning_rate': 0.010696683479330211, 'subsample': 0.6042040593632079, 'colsample_bytree': 0.9886285753904133, 'min_child_weight': 3, 'gamma': 0.07086380801818218}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:20,574] Trial 350 finished with value: 0.5349312414064876 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011288945703701257, 'subsample': 0.6179597663608145, 'colsample_bytree': 0.9731650606398446, 'min_child_weight': 3, 'gamma': 0.07900709868731794}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:21,104] Trial 351 finished with value: 0.5345319156422058 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010153181035582251, 'subsample': 0.6089760678866952, 'colsample_bytree': 0.9754640993850815, 'min_child_weight': 3, 'gamma': 0.08640710140471063}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:21,621] Trial 352 finished with value: 0.5341896430791068 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.010915973510159332, 'subsample': 0.6144358762019295, 'colsample_bytree': 0.9775594748560081, 'min_child_weight': 3, 'gamma': 0.0755500717595516}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:22,124] Trial 353 finished with value: 0.5345319113032295 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010594590335539169, 'subsample': 0.6238224194281217, 'colsample_bytree': 0.9816372785190951, 'min_child_weight': 3, 'gamma': 0.06572719515566446}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:22,629] Trial 354 finished with value: 0.5348646885587662 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.01153505103188612, 'subsample': 0.6108195961126027, 'colsample_bytree': 0.9908685073010491, 'min_child_weight': 7, 'gamma': 0.057661079991306506}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:23,145] Trial 355 finished with value: 0.5337808011259383 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011213694809226236, 'subsample': 0.6485861116662508, 'colsample_bytree': 0.9789673021017824, 'min_child_weight': 6, 'gamma': 0.07296795651453687}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:23,659] Trial 356 finished with value: 0.5345604324801001 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011000406655972733, 'subsample': 0.6043889833576549, 'colsample_bytree': 0.9853797820402691, 'min_child_weight': 3, 'gamma': 0.07930291739269012}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:24,168] Trial 357 finished with value: 0.5349217311836938 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010753195516081381, 'subsample': 0.6193188372102166, 'colsample_bytree': 0.9765905537159357, 'min_child_weight': 3, 'gamma': 0.08280563891234195}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:24,685] Trial 358 finished with value: 0.5341896240960847 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011726963392882405, 'subsample': 0.7957436214532321, 'colsample_bytree': 0.9592182681046839, 'min_child_weight': 3, 'gamma': 0.06911772563607937}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:25,200] Trial 359 finished with value: 0.53448437998584 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.010417143061365746, 'subsample': 0.6138638348009675, 'colsample_bytree': 0.9837013168756993, 'min_child_weight': 3, 'gamma': 0.09121464842113822}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:25,708] Trial 360 finished with value: 0.5347410895606987 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011295147110896098, 'subsample': 0.6085394245225719, 'colsample_bytree': 0.9974119364683498, 'min_child_weight': 3, 'gamma': 0.15688775233391397}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:26,236] Trial 361 finished with value: 0.5345319164557639 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.010923767448471303, 'subsample': 0.6164946974038749, 'colsample_bytree': 0.9883864064256865, 'min_child_weight': 3, 'gamma': 0.07694160149089098}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:26,764] Trial 362 finished with value: 0.5342752087792072 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.01148390661535563, 'subsample': 0.6037475785718079, 'colsample_bytree': 0.9810333397960587, 'min_child_weight': 3, 'gamma': 0.08686686917682374}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:27,283] Trial 363 finished with value: 0.5350168114455646 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011956042635691095, 'subsample': 0.6081463905225741, 'colsample_bytree': 0.9928674114279751, 'min_child_weight': 5, 'gamma': 0.0722185564319854}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:27,807] Trial 364 finished with value: 0.5344368410752416 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.011863834538758012, 'subsample': 0.6071117362100414, 'colsample_bytree': 0.9919231917482699, 'min_child_weight': 5, 'gamma': 0.14188665913366805}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:28,331] Trial 365 finished with value: 0.5347125648584097 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.012049552082706206, 'subsample': 0.6095753784165341, 'colsample_bytree': 0.9967387080542846, 'min_child_weight': 5, 'gamma': 0.07078537750540309}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:28,844] Trial 366 finished with value: 0.5349787849272484 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011697361313500318, 'subsample': 0.6057188300075147, 'colsample_bytree': 0.9925929733735719, 'min_child_weight': 5, 'gamma': 0.06447845548498363}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:29,361] Trial 367 finished with value: 0.5336857203216955 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011933542382505146, 'subsample': 0.7241219256944912, 'colsample_bytree': 0.9952538295933971, 'min_child_weight': 5, 'gamma': 0.059803145696323196}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:29,905] Trial 368 finished with value: 0.5347791174349451 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.011603964329903998, 'subsample': 0.6117484637968893, 'colsample_bytree': 0.9933456384542289, 'min_child_weight': 5, 'gamma': 0.062244735900625216}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:30,456] Trial 369 finished with value: 0.5347791204179914 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.011796059984592966, 'subsample': 0.6072227558022332, 'colsample_bytree': 0.9900686908314856, 'min_child_weight': 5, 'gamma': 0.16871980422993824}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:30,973] Trial 370 finished with value: 0.5335145815994715 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011230038620195604, 'subsample': 0.7104886760555353, 'colsample_bytree': 0.9930801724251355, 'min_child_weight': 5, 'gamma': 0.06698572141772431}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:31,492] Trial 371 finished with value: 0.5346079754584889 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.012247471386389597, 'subsample': 0.603031200933813, 'colsample_bytree': 0.9904310011762655, 'min_child_weight': 7, 'gamma': 0.06423915034658977}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:32,006] Trial 372 finished with value: 0.5348741901036071 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011981970772043023, 'subsample': 0.6197165651557509, 'colsample_bytree': 0.9939384651419603, 'min_child_weight': 5, 'gamma': 0.0732998020827092}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:32,546] Trial 373 finished with value: 0.5344463499421054 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011607382889907135, 'subsample': 0.6142700138245294, 'colsample_bytree': 0.987285004885838, 'min_child_weight': 5, 'gamma': 0.1762413007207599}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:33,051] Trial 374 finished with value: 0.5345794518409438 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011068589822261797, 'subsample': 0.6107418813880948, 'colsample_bytree': 0.9953771515500665, 'min_child_weight': 5, 'gamma': 0.06771313580998146}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:33,577] Trial 375 finished with value: 0.5347315801514629 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011370106622008188, 'subsample': 0.6078571203968484, 'colsample_bytree': 0.986114625111315, 'min_child_weight': 5, 'gamma': 0.0739624619224439}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:34,087] Trial 376 finished with value: 0.5347791090281783 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010789765955815293, 'subsample': 0.6222303691401961, 'colsample_bytree': 0.9918656937610473, 'min_child_weight': 6, 'gamma': 0.07020160483375322}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:34,607] Trial 377 finished with value: 0.5332959012547891 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.011699536682306272, 'subsample': 0.7562370329469063, 'colsample_bytree': 0.9877611886396351, 'min_child_weight': 5, 'gamma': 0.07699511901564643}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:35,144] Trial 378 finished with value: 0.5345129079423613 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011092274489720357, 'subsample': 0.6167522915701634, 'colsample_bytree': 0.982933059102571, 'min_child_weight': 5, 'gamma': 0.05562549998727449}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:35,654] Trial 379 finished with value: 0.534883698699285 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.010797099326158369, 'subsample': 0.611690547838516, 'colsample_bytree': 0.9889763415884278, 'min_child_weight': 4, 'gamma': 0.06356556813944034}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:36,166] Trial 380 finished with value: 0.5347030546356157 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.01132723805763593, 'subsample': 0.6031214043822616, 'colsample_bytree': 0.9996322378911122, 'min_child_weight': 5, 'gamma': 0.08159053626802013}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:36,681] Trial 381 finished with value: 0.5346174913761894 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.012148808811935835, 'subsample': 0.6072987992088501, 'colsample_bytree': 0.9925030333242585, 'min_child_weight': 5, 'gamma': 0.07359888434868504}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:37,203] Trial 382 finished with value: 0.5343132439754763 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011011098516995894, 'subsample': 0.6154805269783361, 'colsample_bytree': 0.9843598108133286, 'min_child_weight': 4, 'gamma': 0.06822601160068546}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:37,710] Trial 383 finished with value: 0.5331057662225339 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.01654493054516129, 'subsample': 0.6111176633327811, 'colsample_bytree': 0.9946839455718774, 'min_child_weight': 5, 'gamma': 0.08437546142290984}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:38,543] Trial 384 finished with value: 0.5318222378736334 and parameters: {'n_estimators': 117, 'max_depth': 5, 'learning_rate': 0.011559922815980622, 'subsample': 0.6186847115953371, 'colsample_bytree': 0.9790422284499755, 'min_child_weight': 3, 'gamma': 0.07784328293861832}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:39,097] Trial 385 finished with value: 0.534294229495981 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.01063827617172069, 'subsample': 0.602765341957372, 'colsample_bytree': 0.9722733978084788, 'min_child_weight': 6, 'gamma': 0.07084896549422498}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:39,615] Trial 386 finished with value: 0.5348171463939355 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011896449649329394, 'subsample': 0.6070491854256125, 'colsample_bytree': 0.9812209801663494, 'min_child_weight': 5, 'gamma': 0.08992931680452629}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:40,126] Trial 387 finished with value: 0.5333339424171508 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010352108914163225, 'subsample': 0.6541238909924435, 'colsample_bytree': 0.9904796294849573, 'min_child_weight': 3, 'gamma': 0.06505902696835575}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:40,642] Trial 388 finished with value: 0.5343702884987062 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011160969100575905, 'subsample': 0.6134909314524337, 'colsample_bytree': 0.9745818314475283, 'min_child_weight': 5, 'gamma': 0.07522618699909336}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:41,175] Trial 389 finished with value: 0.5341801274325922 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.01080155896847502, 'subsample': 0.6280242383277104, 'colsample_bytree': 0.9791271496708012, 'min_child_weight': 3, 'gamma': 0.08116970005236615}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:41,686] Trial 390 finished with value: 0.5341611159361433 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.01134459138755667, 'subsample': 0.6238090048945272, 'colsample_bytree': 0.9859293380764131, 'min_child_weight': 5, 'gamma': 0.08405744376850723}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:42,193] Trial 391 finished with value: 0.5340185054416269 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010569754580907871, 'subsample': 0.6097242533710968, 'colsample_bytree': 0.9407431296312466, 'min_child_weight': 3, 'gamma': 0.07176507014718007}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:42,721] Trial 392 finished with value: 0.534607986034744 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.010973728870036378, 'subsample': 0.6169852919567235, 'colsample_bytree': 0.988999146181015, 'min_child_weight': 5, 'gamma': 0.07802022948167264}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:43,263] Trial 393 finished with value: 0.5349122271981784 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011643116047388814, 'subsample': 0.6033493766794035, 'colsample_bytree': 0.9823586284126413, 'min_child_weight': 3, 'gamma': 0.06053706782478687}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:43,785] Trial 394 finished with value: 0.5346840428679808 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.012035172151402715, 'subsample': 0.6129439801933182, 'colsample_bytree': 0.9842522336943571, 'min_child_weight': 5, 'gamma': 0.06685298045545547}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:44,297] Trial 395 finished with value: 0.5336001500114325 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010020850853520029, 'subsample': 0.6773524853459734, 'colsample_bytree': 0.9967853241502744, 'min_child_weight': 3, 'gamma': 0.0879611125486702}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:44,827] Trial 396 finished with value: 0.5346840425967948 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012531399101084008, 'subsample': 0.6083293279524826, 'colsample_bytree': 0.9766624174835266, 'min_child_weight': 7, 'gamma': 0.048613557540817226}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:45,353] Trial 397 finished with value: 0.5347315731006262 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011230968321647059, 'subsample': 0.6216028708826082, 'colsample_bytree': 0.9801595574486511, 'min_child_weight': 5, 'gamma': 0.13376795580492631}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:45,871] Trial 398 finished with value: 0.5343512772734432 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010876167533645982, 'subsample': 0.6150226321983742, 'colsample_bytree': 0.9939115479411887, 'min_child_weight': 3, 'gamma': 0.09390126435100013}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:46,382] Trial 399 finished with value: 0.5344178176466073 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010627374358194953, 'subsample': 0.6062578216491125, 'colsample_bytree': 0.9439525440624587, 'min_child_weight': 5, 'gamma': 0.07575303168827924}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:46,925] Trial 400 finished with value: 0.5346650286596716 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011488545613826801, 'subsample': 0.6117387464995403, 'colsample_bytree': 0.9919093448284487, 'min_child_weight': 3, 'gamma': 0.0814134516370344}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:47,531] Trial 401 finished with value: 0.5330582189051688 and parameters: {'n_estimators': 97, 'max_depth': 4, 'learning_rate': 0.010331755671253802, 'subsample': 0.7873550670461756, 'colsample_bytree': 0.9742715932741797, 'min_child_weight': 3, 'gamma': 0.0713052067018976}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:48,049] Trial 402 finished with value: 0.5345794569934784 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011747442535649565, 'subsample': 0.6178672612373071, 'colsample_bytree': 0.9864652461498015, 'min_child_weight': 5, 'gamma': 0.07756532422546719}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:48,560] Trial 403 finished with value: 0.5349502526317506 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011128737131017094, 'subsample': 0.6031387805219011, 'colsample_bytree': 0.970911046515772, 'min_child_weight': 4, 'gamma': 0.08545661620468127}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:49,107] Trial 404 finished with value: 0.5345033982619395 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.010901311751844986, 'subsample': 0.6099097449336508, 'colsample_bytree': 0.9781381299530127, 'min_child_weight': 5, 'gamma': 0.06811268254761066}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:49,615] Trial 405 finished with value: 0.5343702830749855 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012257251334305464, 'subsample': 0.6148253672443148, 'colsample_bytree': 0.9823422697687781, 'min_child_weight': 3, 'gamma': 0.05349682920953645}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:50,128] Trial 406 finished with value: 0.5348456708250386 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011422200500997268, 'subsample': 0.6072412760379625, 'colsample_bytree': 0.9523556757962306, 'min_child_weight': 5, 'gamma': 0.07341139596433366}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:50,632] Trial 407 finished with value: 0.5349027148058964 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.01057616366959865, 'subsample': 0.6192420297363185, 'colsample_bytree': 0.9902689136572689, 'min_child_weight': 6, 'gamma': 0.07959078084220794}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:51,193] Trial 408 finished with value: 0.53453191672695 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010992040514463232, 'subsample': 0.6113071556722276, 'colsample_bytree': 0.9845845377658438, 'min_child_weight': 3, 'gamma': 0.0626438639449696}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:51,714] Trial 409 finished with value: 0.5346935509212866 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011897756228339725, 'subsample': 0.6062478478160732, 'colsample_bytree': 0.9803772296295867, 'min_child_weight': 3, 'gamma': 0.08341287435060622}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:52,234] Trial 410 finished with value: 0.5340185051704409 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.01072408232180249, 'subsample': 0.6139076398883142, 'colsample_bytree': 0.9775237221695748, 'min_child_weight': 5, 'gamma': 0.07436925760749327}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:52,766] Trial 411 finished with value: 0.5336762209463426 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.01121540083042447, 'subsample': 0.7002480565736866, 'colsample_bytree': 0.9880292111945775, 'min_child_weight': 3, 'gamma': 0.08822274496933108}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:53,275] Trial 412 finished with value: 0.5342466908565687 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.01019364922001348, 'subsample': 0.6033435457014644, 'colsample_bytree': 0.9945883413982888, 'min_child_weight': 5, 'gamma': 0.06709703656598781}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:53,790] Trial 413 finished with value: 0.534227662004214 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.01153005380348916, 'subsample': 0.622073987278807, 'colsample_bytree': 0.9731416502195792, 'min_child_weight': 5, 'gamma': 0.07077187995643865}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:54,354] Trial 414 finished with value: 0.5344083182712546 and parameters: {'n_estimators': 112, 'max_depth': 3, 'learning_rate': 0.010534733673183782, 'subsample': 0.6088377771041146, 'colsample_bytree': 0.9978618743743634, 'min_child_weight': 3, 'gamma': 0.05814537390977688}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:54,904] Trial 415 finished with value: 0.5342752114910675 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.011090473947123439, 'subsample': 0.6165565276711434, 'colsample_bytree': 0.9748508875531982, 'min_child_weight': 5, 'gamma': 0.08083368422232975}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:55,411] Trial 416 finished with value: 0.5331532999805978 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.018626119538096838, 'subsample': 0.6116713027714827, 'colsample_bytree': 0.9826161154983444, 'min_child_weight': 7, 'gamma': 0.07620776722966724}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:56,019] Trial 417 finished with value: 0.5337903238232896 and parameters: {'n_estimators': 98, 'max_depth': 4, 'learning_rate': 0.0116455422853146, 'subsample': 0.693521987042791, 'colsample_bytree': 0.9389766746369846, 'min_child_weight': 3, 'gamma': 0.06366616941737703}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:56,535] Trial 418 finished with value: 0.5325828552906721 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.023859562611538303, 'subsample': 0.6030694925917592, 'colsample_bytree': 0.9793496356715522, 'min_child_weight': 3, 'gamma': 0.07231233106246929}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:57,093] Trial 419 finished with value: 0.5344083104068598 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.0137606168887403, 'subsample': 0.6187412228882473, 'colsample_bytree': 0.992740637964994, 'min_child_weight': 5, 'gamma': 0.09354033642159658}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:57,610] Trial 420 finished with value: 0.5337903067385699 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010842390042756826, 'subsample': 0.6258635181097272, 'colsample_bytree': 0.986427263347573, 'min_child_weight': 3, 'gamma': 0.08009471190507034}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:58,124] Trial 421 finished with value: 0.5349597614986144 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011861283482393662, 'subsample': 0.6065668961361247, 'colsample_bytree': 0.9765889731720533, 'min_child_weight': 5, 'gamma': 0.0855489894705014}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:58,664] Trial 422 finished with value: 0.5342276725804691 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.012084952371430306, 'subsample': 0.6058376449569364, 'colsample_bytree': 0.9477912690837135, 'min_child_weight': 5, 'gamma': 0.08941967470576451}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:59,217] Trial 423 finished with value: 0.5344083136610921 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.012306566281842637, 'subsample': 0.6001299817910715, 'colsample_bytree': 0.9745703593618306, 'min_child_weight': 5, 'gamma': 0.06860900723910754}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:46:59,746] Trial 424 finished with value: 0.5346935511924725 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.011800701124256551, 'subsample': 0.6071113688739912, 'colsample_bytree': 0.9766769837795682, 'min_child_weight': 5, 'gamma': 0.07475359887443517}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:46:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:00,280] Trial 425 finished with value: 0.5348171531735862 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011915155679946568, 'subsample': 0.6138965681508489, 'colsample_bytree': 0.9700465672614604, 'min_child_weight': 5, 'gamma': 0.0778131918377341}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:00,826] Trial 426 finished with value: 0.5346935473958682 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.012749696769569384, 'subsample': 0.6101897508227635, 'colsample_bytree': 0.976366524887033, 'min_child_weight': 5, 'gamma': 0.08545990839160188}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:01,342] Trial 427 finished with value: 0.5337998245545724 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.014965288662531155, 'subsample': 0.6029086693136284, 'colsample_bytree': 0.9729560468181624, 'min_child_weight': 5, 'gamma': 0.06973612435432279}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:01,859] Trial 428 finished with value: 0.5339709627344242 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.012417234299377505, 'subsample': 0.6148058485585179, 'colsample_bytree': 0.9961839721631974, 'min_child_weight': 5, 'gamma': 0.08239616133579021}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:02,370] Trial 429 finished with value: 0.5340755410157177 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011413483799311662, 'subsample': 0.6624257766256703, 'colsample_bytree': 0.990104403131975, 'min_child_weight': 5, 'gamma': 0.07419824035637339}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:02,913] Trial 430 finished with value: 0.5331437976221985 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.01582697046244494, 'subsample': 0.6069091388203236, 'colsample_bytree': 0.9779907827131037, 'min_child_weight': 5, 'gamma': 0.1313046233007001}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:03,439] Trial 431 finished with value: 0.534037508802495 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011774460724275026, 'subsample': 0.6195515035080362, 'colsample_bytree': 0.9757185653332835, 'min_child_weight': 3, 'gamma': 0.07863389077730333}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:03,955] Trial 432 finished with value: 0.5344368399904974 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.012063025360985951, 'subsample': 0.6111507723211913, 'colsample_bytree': 0.9915865764029813, 'min_child_weight': 5, 'gamma': 0.06578452867182635}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:04,487] Trial 433 finished with value: 0.5341611191903756 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011334653498554352, 'subsample': 0.6159547508342239, 'colsample_bytree': 0.9884495493073903, 'min_child_weight': 3, 'gamma': 0.09483358963751261}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:05,004] Trial 434 finished with value: 0.5341706196504725 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.01155953727273, 'subsample': 0.6035137008621424, 'colsample_bytree': 0.945287342016027, 'min_child_weight': 4, 'gamma': 0.09009674235616652}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:05,529] Trial 435 finished with value: 0.5343702852444737 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.010360088024189723, 'subsample': 0.6080207456120768, 'colsample_bytree': 0.9848265615932671, 'min_child_weight': 5, 'gamma': 0.0720136601524273}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:06,055] Trial 436 finished with value: 0.5349787827577602 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.012177294400267798, 'subsample': 0.612209010406232, 'colsample_bytree': 0.9942463395173576, 'min_child_weight': 3, 'gamma': 0.06183158224584102}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:06,583] Trial 437 finished with value: 0.5340755467106244 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.012653103422950892, 'subsample': 0.6217127129799883, 'colsample_bytree': 0.9951424435687561, 'min_child_weight': 3, 'gamma': 0.058339592994343464}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:07,089] Trial 438 finished with value: 0.5345509301217011 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.012363137213233198, 'subsample': 0.6133032852185533, 'colsample_bytree': 0.990733566347029, 'min_child_weight': 3, 'gamma': 0.06559062344014394}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:07,597] Trial 439 finished with value: 0.5349312441183479 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011953541493686697, 'subsample': 0.6172266781117726, 'colsample_bytree': 0.9928122207465536, 'min_child_weight': 3, 'gamma': 0.06242471096930777}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:08,132] Trial 440 finished with value: 0.5349027188736867 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.0121617338100793, 'subsample': 0.6126948927365801, 'colsample_bytree': 0.9948136157259059, 'min_child_weight': 3, 'gamma': 0.06068858586905515}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:08,646] Trial 441 finished with value: 0.5339899739596872 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.010637405337667931, 'subsample': 0.6310530227434141, 'colsample_bytree': 0.9965886665605355, 'min_child_weight': 3, 'gamma': 0.05494337714840845}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:09,166] Trial 442 finished with value: 0.5340280094271422 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.012167220964960748, 'subsample': 0.6237931163154983, 'colsample_bytree': 0.992930946692, 'min_child_weight': 3, 'gamma': 0.0687288450942836}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:09,689] Trial 443 finished with value: 0.534218160730559 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011166760240767366, 'subsample': 0.6062880536549462, 'colsample_bytree': 0.9977805584514611, 'min_child_weight': 3, 'gamma': 0.0643949641859727}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:10,230] Trial 444 finished with value: 0.5348266566167295 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.010820526199844104, 'subsample': 0.6185800525863859, 'colsample_bytree': 0.9882824701249273, 'min_child_weight': 3, 'gamma': 0.06900283891682644}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:10,745] Trial 445 finished with value: 0.5351784426568548 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011782287475940303, 'subsample': 0.6105319068649869, 'colsample_bytree': 0.9831103051727578, 'min_child_weight': 3, 'gamma': 0.08538066475668646}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:11,256] Trial 446 finished with value: 0.5349882889127637 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012515871902495876, 'subsample': 0.6092883020454776, 'colsample_bytree': 0.9992685864107973, 'min_child_weight': 3, 'gamma': 0.08591334812527206}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:11,787] Trial 447 finished with value: 0.5345509287657709 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012310269632703307, 'subsample': 0.6000554306441063, 'colsample_bytree': 0.9995997904777587, 'min_child_weight': 3, 'gamma': 0.09221629903190504}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:12,300] Trial 448 finished with value: 0.534503393922963 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.012692480650245955, 'subsample': 0.6102665594113628, 'colsample_bytree': 0.9965960790462655, 'min_child_weight': 3, 'gamma': 0.08543334966860748}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:12,812] Trial 449 finished with value: 0.5341420965752995 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012398791646890348, 'subsample': 0.6162756257152321, 'colsample_bytree': 0.9985747091722583, 'min_child_weight': 3, 'gamma': 0.08225682470063382}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:13,314] Trial 450 finished with value: 0.5338093225739952 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.012982660942693708, 'subsample': 0.6384795184377663, 'colsample_bytree': 0.9994660669642991, 'min_child_weight': 3, 'gamma': 0.1513418608216782}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:13,850] Trial 451 finished with value: 0.5345319216082984 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.012015067602758082, 'subsample': 0.6109248492802942, 'colsample_bytree': 0.9948184630859914, 'min_child_weight': 3, 'gamma': 0.08950173564165353}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:14,354] Trial 452 finished with value: 0.5342086608128342 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.011679207275430032, 'subsample': 0.6144119010257553, 'colsample_bytree': 0.9927928665923765, 'min_child_weight': 3, 'gamma': 0.0954016478870961}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:14,858] Trial 453 finished with value: 0.5324877807237077 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.025946215407401992, 'subsample': 0.6040014096368178, 'colsample_bytree': 0.9901251454912422, 'min_child_weight': 3, 'gamma': 0.07911237823766999}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:15,368] Trial 454 finished with value: 0.5348456689267365 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012606244143372884, 'subsample': 0.6087273232348095, 'colsample_bytree': 0.9964134160737269, 'min_child_weight': 3, 'gamma': 0.08767193853663705}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:15,898] Trial 455 finished with value: 0.5339234221967097 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.012115024788831943, 'subsample': 0.6209478974150512, 'colsample_bytree': 0.9368111914529704, 'min_child_weight': 3, 'gamma': 0.07704989852521245}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:16,407] Trial 456 finished with value: 0.5340375123279134 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011801423717620841, 'subsample': 0.6145125680902027, 'colsample_bytree': 0.994228841274428, 'min_child_weight': 3, 'gamma': 0.07355506351768744}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:16,921] Trial 457 finished with value: 0.5347220756235757 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011442341317016703, 'subsample': 0.609910243890751, 'colsample_bytree': 0.9870111005513609, 'min_child_weight': 3, 'gamma': 0.08231167441050567}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:17,448] Trial 458 finished with value: 0.5344463447895708 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.011336886854979477, 'subsample': 0.604151158274596, 'colsample_bytree': 0.9821147670865125, 'min_child_weight': 3, 'gamma': 0.08518080558140861}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:17,975] Trial 459 finished with value: 0.5348076443067225 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.012461586960473146, 'subsample': 0.6172131018110214, 'colsample_bytree': 0.9909244945269456, 'min_child_weight': 3, 'gamma': 0.07190881429496176}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:18,487] Trial 460 finished with value: 0.5346460052310374 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011700232898576775, 'subsample': 0.6127327915977125, 'colsample_bytree': 0.941005277288796, 'min_child_weight': 3, 'gamma': 0.09745585672499914}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:19,024] Trial 461 finished with value: 0.5342276698686089 and parameters: {'n_estimators': 103, 'max_depth': 3, 'learning_rate': 0.011117734127813946, 'subsample': 0.6260209353521785, 'colsample_bytree': 0.9832934077325104, 'min_child_weight': 4, 'gamma': 0.07686986157316048}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:19,558] Trial 462 finished with value: 0.5352449887249257 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.012080508008526787, 'subsample': 0.6075249509291052, 'colsample_bytree': 0.9983517072281337, 'min_child_weight': 3, 'gamma': 0.08125890690218117}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:20,062] Trial 463 finished with value: 0.534760103769008 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.01193787255792037, 'subsample': 0.6059005598707994, 'colsample_bytree': 0.9986677141943184, 'min_child_weight': 3, 'gamma': 0.08138441029397964}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:20,571] Trial 464 finished with value: 0.535340073596959 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011534197699978658, 'subsample': 0.6090121147035751, 'colsample_bytree': 0.9982579223547433, 'min_child_weight': 3, 'gamma': 0.08933190422366236}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:21,105] Trial 465 finished with value: 0.5340375017516582 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.010494314751489592, 'subsample': 0.730216315591935, 'colsample_bytree': 0.998774597853406, 'min_child_weight': 3, 'gamma': 0.09120847723669409}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:21,612] Trial 466 finished with value: 0.5343132347551514 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011358127693240983, 'subsample': 0.6201272716669428, 'colsample_bytree': 0.99981954014916, 'min_child_weight': 3, 'gamma': 0.08927241590754886}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:22,125] Trial 467 finished with value: 0.5347600997012175 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011196526720120113, 'subsample': 0.6039802537845034, 'colsample_bytree': 0.9971497765112449, 'min_child_weight': 3, 'gamma': 0.08596593912035183}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:22,658] Trial 468 finished with value: 0.535197456322792 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010250355067641954, 'subsample': 0.6125000360826326, 'colsample_bytree': 0.9977345891224425, 'min_child_weight': 3, 'gamma': 0.13868974389561134}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:23,376] Trial 469 finished with value: 0.5332674112643115 and parameters: {'n_estimators': 95, 'max_depth': 5, 'learning_rate': 0.010039738620783086, 'subsample': 0.6161113169737904, 'colsample_bytree': 0.9999269696589068, 'min_child_weight': 3, 'gamma': 0.09407873590600073}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:23,874] Trial 470 finished with value: 0.5341135759408009 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.010176672430102814, 'subsample': 0.6002798719872071, 'colsample_bytree': 0.997635328539507, 'min_child_weight': 3, 'gamma': 0.10533844074947836}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:24,393] Trial 471 finished with value: 0.5341516016455589 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010453421898905475, 'subsample': 0.6085659941406817, 'colsample_bytree': 0.9965642214748052, 'min_child_weight': 3, 'gamma': 0.12796644112626737}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:25,099] Trial 472 finished with value: 0.5337523008303916 and parameters: {'n_estimators': 119, 'max_depth': 4, 'learning_rate': 0.010430728348759286, 'subsample': 0.6127155000309998, 'colsample_bytree': 0.9981008201263738, 'min_child_weight': 3, 'gamma': 0.14758343506164742}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:25,620] Trial 473 finished with value: 0.5343322495058326 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.010264006389019809, 'subsample': 0.6065471997684114, 'colsample_bytree': 0.9954338949620514, 'min_child_weight': 3, 'gamma': 0.1389074106965325}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:26,138] Trial 474 finished with value: 0.5324307158615259 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.022070310327894572, 'subsample': 0.6182380547212011, 'colsample_bytree': 0.9978950798506331, 'min_child_weight': 3, 'gamma': 0.14044304489820886}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:26,648] Trial 475 finished with value: 0.5344083177288824 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010182044434291979, 'subsample': 0.6099802096443471, 'colsample_bytree': 0.9997939333911494, 'min_child_weight': 3, 'gamma': 0.13506252913505526}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:27,169] Trial 476 finished with value: 0.531955339772472 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.029846719506657484, 'subsample': 0.6220694148291195, 'colsample_bytree': 0.9960373217494879, 'min_child_weight': 3, 'gamma': 0.14764984508728907}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:27,775] Trial 477 finished with value: 0.5341991505900404 and parameters: {'n_estimators': 113, 'max_depth': 3, 'learning_rate': 0.01079632691490133, 'subsample': 0.6147371873082573, 'colsample_bytree': 0.9962096278653503, 'min_child_weight': 3, 'gamma': 0.13703414214542112}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:28,301] Trial 478 finished with value: 0.5346174854100968 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.010657419880995033, 'subsample': 0.6044779102996245, 'colsample_bytree': 0.9935865550802108, 'min_child_weight': 3, 'gamma': 0.1440757977656568}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:28,804] Trial 479 finished with value: 0.5346174856812828 and parameters: {'n_estimators': 93, 'max_depth': 3, 'learning_rate': 0.010987425339914529, 'subsample': 0.6091504895886, 'colsample_bytree': 0.9979249377640966, 'min_child_weight': 3, 'gamma': 0.08915280184482513}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:29,350] Trial 480 finished with value: 0.5348456719097827 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.010374028387047202, 'subsample': 0.6132363168211833, 'colsample_bytree': 0.9951805111531208, 'min_child_weight': 3, 'gamma': 0.13252414562943154}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:29,862] Trial 481 finished with value: 0.5347220712845991 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010993561732555501, 'subsample': 0.6173227875466084, 'colsample_bytree': 0.9973336687135357, 'min_child_weight': 3, 'gamma': 0.08364345180468638}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:30,408] Trial 482 finished with value: 0.5345509293081431 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010613619165084827, 'subsample': 0.6072825628760092, 'colsample_bytree': 0.9996860115652432, 'min_child_weight': 3, 'gamma': 0.08704662152607018}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:30,925] Trial 483 finished with value: 0.534855175624112 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011521582064323771, 'subsample': 0.602979638180016, 'colsample_bytree': 0.9937710331018729, 'min_child_weight': 3, 'gamma': 0.08140781927054924}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:31,466] Trial 484 finished with value: 0.5343227474186195 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011168637477468659, 'subsample': 0.6247994630269382, 'colsample_bytree': 0.9916035208961499, 'min_child_weight': 3, 'gamma': 0.09702600509755285}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:31,978] Trial 485 finished with value: 0.5348741944425837 and parameters: {'n_estimators': 95, 'max_depth': 3, 'learning_rate': 0.010783652928821918, 'subsample': 0.6127153758615508, 'colsample_bytree': 0.9864714606005971, 'min_child_weight': 3, 'gamma': 0.09145453168091158}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:32,512] Trial 486 finished with value: 0.5345604365478906 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.010949401784975006, 'subsample': 0.620294478768416, 'colsample_bytree': 0.9955390088957428, 'min_child_weight': 3, 'gamma': 0.07623972701980589}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:33,074] Trial 487 finished with value: 0.5343322549295532 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.010263304969380632, 'subsample': 0.6002154421519746, 'colsample_bytree': 0.992390555177849, 'min_child_weight': 3, 'gamma': 0.08587016115461353}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:33,584] Trial 488 finished with value: 0.5339329326906896 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.010651247087262776, 'subsample': 0.6101881867882682, 'colsample_bytree': 0.9563037784241315, 'min_child_weight': 3, 'gamma': 0.12928162487873956}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:34,102] Trial 489 finished with value: 0.534474870305418 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011424600324441406, 'subsample': 0.6154801835232895, 'colsample_bytree': 0.986078405176045, 'min_child_weight': 3, 'gamma': 0.08002194329803125}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:34,647] Trial 490 finished with value: 0.53454142857686 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.011723192702718781, 'subsample': 0.606207434039579, 'colsample_bytree': 0.9999874190218233, 'min_child_weight': 3, 'gamma': 0.0745946546821106}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:35,150] Trial 491 finished with value: 0.5326589123950949 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.01817100208445743, 'subsample': 0.6105102104973643, 'colsample_bytree': 0.9891692116114089, 'min_child_weight': 3, 'gamma': 0.08299180056538771}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:35,686] Trial 492 finished with value: 0.5348076467473967 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011184698520367652, 'subsample': 0.6165180228712982, 'colsample_bytree': 0.9840874001050245, 'min_child_weight': 4, 'gamma': 0.09201882663967781}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:36,209] Trial 493 finished with value: 0.5342942224451444 and parameters: {'n_estimators': 101, 'max_depth': 3, 'learning_rate': 0.01047211618664329, 'subsample': 0.6068223456321455, 'colsample_bytree': 0.9427235030453999, 'min_child_weight': 3, 'gamma': 0.07833516758606181}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:36,758] Trial 494 finished with value: 0.5344938874967735 and parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.010877731106666982, 'subsample': 0.6134078684351644, 'colsample_bytree': 0.997476703175393, 'min_child_weight': 3, 'gamma': 0.13587924640915014}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:37,279] Trial 495 finished with value: 0.534807640510118 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.011575785582215085, 'subsample': 0.6030463101716964, 'colsample_bytree': 0.9807061845726209, 'min_child_weight': 3, 'gamma': 0.0877540606693051}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:37,795] Trial 496 finished with value: 0.5338568655523838 and parameters: {'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.011266007395718149, 'subsample': 0.6275918511636082, 'colsample_bytree': 0.9948519517861965, 'min_child_weight': 3, 'gamma': 0.07225182141684645}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:38,340] Trial 497 finished with value: 0.533714260210402 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.010075762427402914, 'subsample': 0.6191508325292772, 'colsample_bytree': 0.9613816684567619, 'min_child_weight': 3, 'gamma': 0.08281057705972698}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:38,872] Trial 498 finished with value: 0.5346650254054391 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011025125924103442, 'subsample': 0.6104073514613975, 'colsample_bytree': 0.9877865895185239, 'min_child_weight': 3, 'gamma': 0.07613153447606068}. Best is trial 329 with value: 0.5353876119651854.\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:47:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-03 16:47:39,474] Trial 499 finished with value: 0.5325353009224701 and parameters: {'n_estimators': 96, 'max_depth': 4, 'learning_rate': 0.01061513469718188, 'subsample': 0.7999488805049917, 'colsample_bytree': 0.9836215786651251, 'min_child_weight': 3, 'gamma': 0.1431359832018232}. Best is trial 329 with value: 0.5353876119651854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.5353876119651854\n",
      "Best Hyperparameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.011740091000547747, 'subsample': 0.6105274311500477, 'colsample_bytree': 0.9762208758572544, 'min_child_weight': 6, 'gamma': 0.08168009726574428}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Use your full feature set\n",
    "X = df_max.drop(columns=[\"target\", \"return_future\",\"timestamp\"], errors=\"ignore\")\n",
    "y = df_max[\"target\"]\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 80, 120),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 5),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.03, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.8),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.9, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 3, 7),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 0.2),\n",
    "        \"random_state\": 42,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"objective\": \"binary:logistic\"\n",
    "    }\n",
    "\n",
    "    # Model with current hyperparams\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    # Cross-validation for robust performance\n",
    "    score = cross_val_score(model, X, y, cv=3, scoring=\"accuracy\").mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=500, timeout=600)\n",
    "print(\"Best Accuracy:\", study.best_value)\n",
    "print(\"Best Hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raph4/crypto-bot/crypto-bot/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:54:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9762208758572544, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None, feature_weights=None,\n",
       "              gamma=0.08168009726574428, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.011740091000547747,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=97, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9762208758572544, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None, feature_weights=None,\n",
       "              gamma=0.08168009726574428, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.011740091000547747,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=97, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9762208758572544, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='logloss', feature_types=None, feature_weights=None,\n",
       "              gamma=0.08168009726574428, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.011740091000547747,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=97, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_params.update({\n",
    "    \"random_state\": 42,\n",
    "    \"use_label_encoder\": False,\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"objective\": \"binary:logistic\"\n",
    "})\n",
    "\n",
    "final_model = XGBClassifier(**best_params)\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_model_optuna.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(final_model, \"xgb_model_optuna.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
